---
title: "Práctica 2"
author: "Lorena Romero y María Soto"
date: "2023-11-22"
output:
  
  html_document:
    df_print: paged
    highlight: kate
    number_sections: yes
    theme: spacelab
    toc: yes
    toc_float: yes
---

```{r}
library(ggplot2)
library(tidyverse)
library(gridExtra)
library(reshape2)
library(GGally)
library(ggfortify)
library(caret)
library(dplyr)
library(FactoMineR)
library(factoextra)
library(plotly)
library(mlbench)
library(rpart.plot)
library(Metrics)
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
colorspie <- c("skyblue", "plum3", "pink2", "sandybrown", "palegreen3")
colorpieborde <- c("skyblue4", "plum4", "pink3", "salmon3", "palegreen4")
```



Sys.setenv(RSTUDIO_PANDOC = "C:/Program Files/RStudio/resources/app/bin/quarto/bin/tools")

rmarkdown::render("Practica2.Rmd")



# Apartado A
## Descripción del conjunto de datos
**Describe brevemente el conjunto de entrenamiento.**

Vamos a trabajar sobre un conjunto de datos en el que se recogen las canciones más populares de Spotify a lo largo de un tiempo. Cada entrada recoge una amplia variedad de información de cada canción que analizaremos más adelante. Nuestro objetivo es utilizar estos datos para predecir la popularidad de canciones.

El conjunto de datos de entrenamiento consta de las siguientes variables categóricas:
`spotify_id`, `name`, `artists`, `country`, `is_explicit`,  `album_name`, `key`, `mode`, `time_signature`

Y, por otra parte, las siguientes variables numéricas:
`daily_rank`, `daily_movement`, `weekly_movement`, `snapshot_date`, `duration_ms`, `danceability`, `energy`, `loudness`, `speechiness`, `accousticness`,`liveness`, `instrumentalness` , `valence`, `tempo`, `popularity` y `album_release_date`

```{r}
spotify <- read.csv("spoti.csv", na.strings = "")

summary(spotify)
```
Sin embargo, aquí ya vemos que hay algunas variables que se toman como numéricas cuando hemos hablado de ellas como categóricas, y las fechas que son leídas como strings. Este problema lo trataremos después. 

Pero para hacer un pequeño análisis haremos un nuevo dataset donde no tendremos en cuenta los países. Después, haremos la media de popularidad de cada canción para ver cómo de populares son las canciones "mundialmente".

```{r}
spotify1 = spotify
#eliminamos columna paises
spotify1 = spotify1[,-c(1,8)]

# Calcula la media de la popularidad para cada canción
mean_popularity <- aggregate(popularity ~ name, data = spotify1, mean)

categories <- cut(spotify1$popularity, breaks = seq(0, 100, by = 10))
barplot(table(categories), main = "Recuento de Canciones por Intervalo de Popularidad", xlab = "Intervalo de Popularidad", ylab = "Recuento", col = colorspie)


```

Viendo este gráfico se nos ocurre para hacer nuestro pequeño análisis 3 grupos principales.

  - **Muy poco populares**, cuyo rango será de 0 a 40, de las canciones existentes hay muy pocas canciones poco populares.
  
  - **Populares**, cuyo rango de popularidad será de 40 a 80, este rango abarca canciones que han sido conocidas.
  
  - **Muy populares**, cuyo rango de popularidad sera de 80 a 100, las canciones más populares y conocidas.
  
Después de haber hecho esta división vamos a seguir haciendo este análisis sin tener en cuenta los países, sino la popularidad "mundial" tras haber hecho la media para no ver en el análisis tantos valores donde la mayoría van a ser repetidos. Para ello ahora vamos a empezar visualizando las variables categóricas que pueden tener algo de relación con `popularity`.

Vamos a utilizar analysis_data, donde en principio no vamos a tener en cuenta el país:
```{r}
#primero convertimos las fechas
spotify1$snapshot_date = as.Date(spotify1$snapshot_date)
spotify1$album_release_date = as.Date(spotify1$album_release_date)

#creamos analysis_data donde hacemos media de todas las variables, ya que si estas tienen algun remix por ejemplo
#cambiaran su valencia, energia pero por muy pocas centesimas.
analysis_data <- aggregate(cbind(popularity, daily_rank, weekly_movement,daily_movement, danceability, energy, loudness, key, speechiness, acousticness, instrumentalness, liveness, valence, tempo, time_signature, duration_ms) ~ name + artists + album_name + is_explicit + album_release_date + mode, data = spotify1, mean)

#ponemos las fechas como minimo, ya que nos interesa cuando entraron a la lista por primera vez
analysis_data2 <- aggregate(cbind(snapshot_date) ~  name + artists + album_name + is_explicit + album_release_date + mode , data = spotify1, min)

analysis_data$snapshot_date = analysis_data2$snapshot_date

analysis_data$popularity_group <- cut(analysis_data$popularity, breaks = c(0, 40, 80, 100), labels = c("Poco Conocida", "Popular", "Muy Popular"),include.lowest = TRUE)
analysis_data$popularity_group <- factor(analysis_data$popularity_group, levels = c("Poco Conocida", "Popular", "Muy Popular"))


```

- Variable `key`
Primero la pasamos a factor ya que actualmente se interpreta como numérica.
```{r}
analysis_data$key = factor(analysis_data$key)
myplot <- ggplot(data = analysis_data, aes(x = key, fill = popularity_group, color = popularity_group)) +
  geom_bar(alpha = 0.8, position = "dodge") +
  ggtitle("Relación entre la clave y la popularidad") +
  labs(x = "Key", y = "", fill = "Popularity Group") +
  scale_color_manual(values = colorpieborde, name = "Popularity Group") +
  scale_fill_manual(values = colorspie, name = "Popularity Group")
myplot

table(analysis_data$popularity_group, analysis_data$key)
```

Podemos ver como las canciones más populares son las que están compuestas en key 1. Esto nos hace pensar que esta variable si que estará relacionada con la popularidad debido a que puede aportar algo a las canciones que las haga más atractivas a pesar de que seguramente la persona que escucha la música no sabe la clave en la que está compuesta.

- `mode`

Analizando esta variable hemos descubierto que hay canciones que tienen un cambio de modo, es decir, que si una canción está en un principio en una tonalidad mayor otra variación de esta, un remix o incluso un error ocasiona que en algunas canciones haya cambios de modo. Entonces, si hacemos la media de esta variable agrupando las canciones por nombre y el resto de variables hay alguna cuyo modo varía, dando así valores intermedios, por lo que en el agrupamiento anteriormente hemos decidido que no se haga la media de esta variable.

```{r}
analysis_data$mode = factor(analysis_data$mode)
myplot <- ggplot(data = analysis_data, aes(x = mode, fill = popularity_group, color = popularity_group)) +
  geom_bar(alpha = 0.8, position = "dodge") +
  ggtitle("Relación entre el modo y la popularidad") +
  labs(x = "Mode", y = "", fill = "Popularity Group") +
  scale_color_manual(values = colorpieborde, name = "Popularity Group") +
  scale_fill_manual(values = colorspie, name = "Popularity Group")
myplot

table(analysis_data$popularity_group, analysis_data$mode)
```

También vemos que aquí hay diferencia de canciones, hay aproximadamente 70 canciones más que son muy populares debido al modo en el que están compuestas. Por otro lado, hay casi 200 canciones más que son populares compuestas en el modo 0. Sin embargo, hay más canciones en el modo 1 que tienen cierta popularidad que en el modo 0.
Por lo que esta variable también puede estar relacionada.


- `is_explicit`

```{r}
analysis_data$is_explicit = factor(analysis_data$is_explicit)
myplot <- ggplot(data = analysis_data, aes(x = is_explicit, fill = popularity_group, color = popularity_group)) +
  geom_bar(alpha = 0.8, position = "dodge") +
  ggtitle("Relación entre el modo y la popularidad") +
  labs(x = "Explicita", y = "", fill = "Popularity Group") +
  scale_color_manual(values = colorpieborde, name = "Popularity Group") +
  scale_fill_manual(values = colorspie, name = "Popularity Group")
myplot

table(analysis_data$popularity_group, analysis_data$is_explicit)
```
La mayoría de canciones no explícitas son más populares que las canciones explícitas, por lo que quizás esto también juega un papel importante en la popularidad.

- `name`, `artists`, `album_name` 
Aunque estas variables no van a jugar un papel fundamental en nuestro modelo, es más, vamos a prescindir de ellas ya que lo que pretendemos es saber si una canción se hará o no famosa debido a sus atributos intrínsecos. Vamos a mostrar las canciones más populares, los artistas, y el nombre del album

```{r}
analysis_datasorted = analysis_data[order(-analysis_data$popularity),]

N<-10
artistastop = analysis_datasorted$artists[1:10]
cat("Artistas más populares\n")
artistastop
```
Estos son el top de artistas con más popularidad en este momento. Cada uno tiene diferentes canciones populares:

```{r}
popularity_counts <- table(analysis_datasorted$artists)

cat("Número de canciones en el dataset para cada artista:\n")
for (artist in artistastop) {
  cat(artist, ":", popularity_counts[artist], "canciones en la lista\n")
}
```
Y estas son las canciones y el nombre del álbum:
```{r}
canciones <- data.frame(
  Artista = analysis_datasorted$artists[1:10],
  Nombre = analysis_datasorted$name[1:10],
  Álbum = analysis_datasorted$album_name[1:10]
)
canciones
```
Esto no coincide con el ranking y somos conscientes de ello pero todavía no hemos analizado esas partes. Como recordatorio, esto solo lo hemos hecho para hablar un poco de los datos, estas tres variables no las vamos a tener muy en cuenta de ahora en adelante.

***Variables continuas***

- `daily_rank`

```{r}
analysis_data$daily_rank = round(analysis_data$daily_rank)

analysis_data$daily_rank_group <- cut(analysis_data$daily_rank, breaks = c(0, 10, 20, 30, 40, 50), labels = c("Top 10", "Top 20", "Top 30", "Top 40", "Top 50"),include.lowest = TRUE)

myplot = ggplot(data=analysis_data, aes(x=daily_rank_group, fill=popularity_group, color = popularity_group)) +
  geom_bar(alpha=0.8, position="dodge")+
  labs(x = "Daily_Rank",y="") +
  scale_color_manual(values = colorpieborde, name="popularity")+
  scale_fill_manual(values = colorspie, name="popularity")
myplot
```
Esto nos hace pensar que el ranking actual no significa que una canción sea muy popular. Estas van a ir ganando popularidad quizás con el tiempo que permanezca en la lista, pero las 10 primeras no se acercan en absoluto a las canciones más populares. 

- `daily_movement`

```{r}
analysis_data$daily_movement = round(analysis_data$daily_movement)

analysis_data$daily_movement_group <- cut(analysis_data$daily_movement, breaks = c(-10, 0, 5, 10, 20, 30, 40, 50), labels = c("Baja puestos", "Se mantiene", "Sube puestos", "Sube bastantes puestos", "Sube muchos", "Se hace famosísima de repente", "Da un boom"),include.lowest = TRUE)

myplot = ggplot(data=analysis_data, aes(x=daily_movement_group, fill=popularity_group, color = popularity_group)) +
  geom_bar(alpha=0.8, position="dodge")+
  labs(x = "Daily Movemente",y="") +
  scale_color_manual(values = colorpieborde, name="popularity")+
  scale_fill_manual(values = colorspie, name="popularity")+
  theme(axis.text.x = element_text(angle = 15, hjust = 1))
myplot
```
El movimiento diario nos muestra que las canciones que se mantienen son las más populares, esto es seguramente por aguantar más tiempo en un ranking superior.

- `weekly_movement`

```{r}
analysis_data$weekly_movement = round(analysis_data$weekly_movement)

analysis_data$weekly_movement_group <- cut(analysis_data$weekly_movement, breaks = c(-20, 0, 5, 10, 20, 30, 40, 80), labels = c("Baja puestos", "Se mantiene", "Sube puestos", "Sube bastantes puestos", "Sube muchos", "Se hace famosísima de repente", "Da un boom"),include.lowest = TRUE)

myplot = ggplot(data=analysis_data, aes(x=weekly_movement_group, fill=popularity_group, color = popularity_group)) +
  geom_bar(alpha=0.8, position="dodge")+
  labs(x = "Weekly Movemente",y="") +
  scale_color_manual(values = colorpieborde, name="popularity")+
  scale_fill_manual(values = colorspie, name="popularity")+
  theme(axis.text.x = element_text(angle = 15, hjust = 1))
myplot
```
Aquí vemos que para algunas canciones hay NA's pero este análisis no es con el conjunto de datos definitivo que vamos a tratar por lo que no las estamos teniendo en cuenta. Podemos ver como al igual que antes son las canciones que se mantienen las que más populares son.


- `snapshot_date` interesante análisis junto `album_realease_date`

Creemos que es interesante analizar el tiempo que tarda una canción en entrar en el dataset porque va a empezar a ganar popularidad para ello vamos a hacer una columna con el número de días que una canción tarda en hacerse famosa

```{r}
analysis_data$snapshot_date = as.Date(analysis_data$snapshot_date)
analysis_data$album_release_date = as.Date(analysis_data$album_release_date)

diferencia_dias = as.numeric(analysis_data$snapshot_date - analysis_data$album_release_date)
analysis_data$numDiasFama = diferencia_dias

analysis_data$numDiasFama = ifelse(analysis_data$numDiasFama <= 0, 0, analysis_data$numDiasFama)

analysis_data$numDiasFama_group <- cut(analysis_data$numDiasFama, breaks = c(-1, 1, 10, 30, 60, 90, 120, 99999), labels = c("Entra al salir", "10 dias", "1 mes", "2 meses", "3 meses", "4 meses", "+"),include.lowest = TRUE)
sum(is.na(analysis_data$numDiasFama))
sum(is.na(analysis_data$numDiasFama_group))
myplot = ggplot(data=analysis_data, aes(x=numDiasFama_group, fill=popularity_group, color = popularity_group)) +
  geom_bar(alpha=0.8, position="dodge")+
  labs(x = "Número Días Hasta Dataset",y="") +
  scale_color_manual(values = colorpieborde, name="popularity")+
  scale_fill_manual(values = colorspie, name="popularity")
myplot
```
Son muy pocas las canciones que nada más salir entran al dataset de spotify. La mayoría de canciones que entran tienen mucha antigüedad siendo gran parte bastante populares. Además, cabe destacar que la popularidad de las que entran a los 10 dias de salir es baja.


- **CARACTERÍSTICAS DE LAS CANCIONES**
`duration_ms`, `danceability`, `energy`, `loudness`, `speechiness`, `accousticness`, `liveness`, `instrumentalness`, `valence`, `tempo`, `time_signature`

```{r}
analysisContinuas= analysis_data[ , c("popularity_group", "duration_ms", "danceability","energy", "loudness", "speechiness", "acousticness", "liveness", "instrumentalness", "valence", "tempo")]
mymelt=melt(analysisContinuas, id.vars=1, value.name="FeatureValue", variable.name="Feature")

myplot = ggplot(data=mymelt, aes(x=FeatureValue, fill=popularity_group, color = popularity_group)) +
  geom_density(alpha=0.8)+
  ggtitle("Relación entre las variables continuas y la variable de clase")+
  labs(x = "",y="", fill = "") +
  scale_color_manual(values = colorpieborde, name="")+
  scale_fill_manual(values = colorspie, name="")+
  facet_wrap(~ Feature, ncol=3, scales = "free")
myplot
```
Nos sorprende ver que todas estas variables parecen tener una gran correlación con la variable de clase. Ya que podemos verlas todas superpuestas. Sin embargo, vemos que hay valores muy dispersos y nos gustaría trabajar con ellos, quizá, en la misma escala; es por esto que más adelante seguramente se normalicen estos valores.

Creemos que además de con la popularidad, estas variables van a estar bastante correlacionadas entre sí.

```{r}
analysisContinuas= analysis_data[ , c("duration_ms", "danceability","energy", "loudness", "speechiness", "acousticness", "liveness", "instrumentalness", "valence", "tempo")]
corrplot::corrplot(cor(analysisContinuas))

```
Y tal como imaginamos podemos ver la relación que existe entre estas variables. Por ejemplo la relación negativa que hay entre `acousticness` y `energy` que puede ser debido a que el acústico transmite menos energía. O que las canciones donde hay energía sean más "ruidosas". Nos parece muy interesante que, en general, la mayoría están relacionadas.


- Por último, `time_signature`
```{r}
myplot = ggplot(data=analysis_data, aes(x=time_signature, fill=popularity_group, color = popularity_group)) +
  geom_bar(alpha=0.8, position="dodge")+
  labs(x = "Time Signature",y="") +
  scale_color_manual(values = colorpieborde, name="popularity")+
  scale_fill_manual(values = colorspie, name="popularity")
myplot
```
Vemos como casi todas las canciones tienen un `time_signature` de 4, y que no hay ninguna con 2. Por lo tanto seguramente esta variable sea un poco indiferente a la hora de conocer la popularidad. Pero nos ayudará a determinar que la mayoría de canciones se hacen populares cuando su `time_signature` es de 4.


*TODO*
Antes de comenzar con las preguntas del apartado 1, nos gustaría hacer un pequeño PCA para mostrar si con las variables que tenemos numéricas seríamos capaces de determinar algo de información sobre la popularidad.

```{r}
analysis_pca = analysisContinuas
analysis_pca$daily_rank = analysis_data$daily_rank
analysis_pca$weekly_movement = analysis_data$weekly_movement 
analysis_pca$daily_movement = analysis_data$daily_movement
analysis_pca$time_signature = analysis_data$time_signature
analysis_pca$numDiasFama = analysis_data$numDiasFama
analysis_pca_estatus = analysis_data$popularity_group

# PCA
pca_result <- prcomp(analysis_pca, scale = TRUE)
row.names(pca_result$x) = analysis_pca_estatus
pcas = as.data.frame(pca_result$x, stringsAsFactors =F)
pcas = cbind(ESTATUS = analysis_pca_estatus,pcas)
```

```{r}
ggplot(pcas, aes(PC1, PC2, color = ESTATUS, shape=ESTATUS)) +
  geom_point(size = 1, alpha=0.6) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  geom_vline(xintercept = 0, linetype = "dashed") +
  scale_color_manual(values = colorspie) +
  scale_shape_manual(values = c(17, 16, 15)) +
  xlab("Primera componente principal") +
  ylab("Segunda componente principal") +
  ggtitle("Las dos primeras componentes principales de titanicData") +
  guides(color = guide_legend(title = "Estado de Popularidad"), shape = guide_legend(title = "Estado de Popularidad")) +
  theme_minimal() +
  theme(legend.position = "top")
```

```{r}
autoplot(pca_result, data=analysis_data, cex = 0.7, alpha=0.6, color = "popularity_group",
         loadings = TRUE, loadings.colour = 'gold',
         loadings.label = TRUE, loadings.label.size = 4, loadings.label.colour = 'mediumvioletred')

fviz_pca_var(pca_result, col.var = "contrib",
             gradient.cols = c("white", "blue", "red"), 
             repel = TRUE)
```

Debido a la gran cantidad de datos es casi imposible ver lo que nos muestra este PCA, aunque podemos ver la parte representativa de cada componente en el análisis. También se nos dice que variables como weekly_movement, energy, loudness... Presentan una gran variación para nuestros datos.

```{r}
(VE <- pca_result$sdev^2)
PVE <- VE / sum(VE)
cumsum(round(PVE, 2))
```
Vemos que con 11 de estas variables ya seríamos capaces de procesar un 98% de la popularidad. Y eso que solo estamos trabajando con las numéricas, 12 variables sobre las 26 disponibles inicialmente son muy buenas para entrenar un modelo. Lo que nos lleva a pensar que quizás no necesitemos de las otras variables para hacer un buen trabajo.

Finalmente vamos a analizar un poco de la variable `country` la que hemos eliminado anteriormente sin tener reparo en que esta variable tendrá canciones con popularidad distinta en cada país, vamos a quedarnos con aquellas con mayor popularidad y por lo tanto vamos a ver solo un poco de como afectan las variables numéricas a los distintos países.
*TODO*

```{r, eval=FALSE}
library(rnaturalearth)
library(ggplot2)
library(purrr)
library(cowplot)

analysis_data <- aggregate(cbind(popularity, daily_rank, weekly_movement,daily_movement, danceability, energy, loudness, key, speechiness, acousticness, instrumentalness, liveness, valence, tempo, time_signature, duration_ms) ~ name + artists + album_name + is_explicit + album_release_date + mode + country, data = spotify, mean)

analysis_data2 <- aggregate(cbind(snapshot_date) ~  name + artists + album_name + is_explicit + album_release_date + mode + country , data = spotify, min)

analysis_data$snapshot_date = analysis_data2$snapshot_date

# Cargar datos de límites de países
world <- ne_countries(returnclass = "sf")

world = world[, c("iso_a2", "geometry")]

# Crear un conjunto de datos de ejemplo
spotify_mean <- data.frame(
  country= analysis_data$country,
  popularity = analysis_data$popularity,
  is_explicit = analysis_data$is_explicit,
  duration_ms = analysis_data$duration_ms, 
  danceability = analysis_data$danceability,
  energy = analysis_data$energy,
  loudness = analysis_data$loudness,
  speechiness = analysis_data$speechiness,
  liveness = analysis_data$liveness,  
  instrumentalness = analysis_data$instrumentalness,
  valence = analysis_data$valence, 
  tempo = analysis_data$tempo
)

# Quedarse con las filas en las que la popularidad es mayor que 80
spotify_mean <- spotify_mean[spotify_mean$popularity > 80, ]

# Unir datos de Spotify con datos del mundo
world_spotify <- merge(world, spotify_mean, by.x = "iso_a2", by.y = "country", all.x = FALSE)

# Lista de variables a usar en cada mapa
variables <- c("duration_ms", "danceability", "energy", "loudness", "speechiness", "liveness", "valence", "tempo")

# Crear una lista de gráficos usando purrr::map
maps <- map(variables, function(var) {
  ggplot() +
    geom_sf(data = world_spotify, aes_string(fill = var)) +
    scale_fill_gradient(low = "lightyellow", high = "sandybrown") +
    theme_minimal() +
    labs(title = var)  # Título con el nombre de la variable
})

plot_grid(plotlist = maps, ncol = 3)
```

Aquí podemos ver como la `danceability` de las canciones más populares sera distinta en cada país. Y otras características como por ejemplo la `valence` en Oceanía disfrutaran de canciones más calmadas que por ejemplo en sur América.

```{r}
rm(analysis_data, analysis_data2, analysis_datasorted,mean_popularity, canciones, mymelt, artist, pcas, pca_result, spotify_mean, spotify1, world, world_spotify, myplot, maps, analysisContinuas, analysis_pca, analysis_pca_estatus, artistastop, categories, diferencia_dias, N, popularity_counts, PVE, variables, VE)
```

Después de haber hecho este pequeño análisis, cuyos datos son una muestra representativa del conjunto inicial pasamos a responder las preguntas del apartado A.

**Describe además, los atributos predictores del conjunto y la variable a predecir. Divide la descripción de los atributos en cuatro grupos, a saber. Justifica el porqué entiendes que cada atributo tiene o no relación con `popularity`.**

**1. predictores numéricos que, a priori, no tienen relación alguna con `popularity` y por tanto no son útiles para su predicción.**

Vamos a nombrar cada variable que pensamos que no tienen relación con su correspondiente justificación.

- `album_release_date`: no estamos muy seguras de si esta variable se tratará más adelante o si tendrá relación con la popularidad.
- `snapshot_date`: La fecha en la que se recogieron los datos podría ser importante porque la popularidad de una canción puede variar con el tiempo aunque no estamos muy seguro de ellos.

**2. Predictores numéricos que pueden aportar algo a la predicción de `popularity` y predictores categóricos.**

Como hemos hecho en el apartado anterior, vamos ir explicanco junto a la variable que creemos que sí puede aportar el porqué de esta creencia.

Para los predictores numéricos:

- `daily_rank`: La posición diaria en el ranking puede ser un indicador importante de la popularidad de una canción. Si una canción ocupa constantemente un lugar alto es probable que sea popular.

- `daily_movement`: El cambio diario de la posición podría indicar tendencias en la popularidad de la canción, en caso de subir seguramente indique un aumento de popularidad.

- `weekly_movement`: Es parecido al anterior, pero a más largo plazo.

- `valence`: La media de positivismo transmitido por la canción podría influir en su atractivo general, las cancioens más alegres o las más triste suelen ser las más populares pero si no trasmites nada seguramente no sea popular.

- `tempo`: El número de beats por minuto puede influir en la percepción de energía de una canción y ser más popular.

- `energy`: La energía de la canción podría ser un factor calve en su atractivo puesto que las canciones más enérgicas podrían tener mayor probabilidad de ser populares.

- `time_signature`: Creemos que el nivel en una esacala de ritmo musical tiene relación con las dos anteriores por lo que pensamos que puede ser relevante para la popularidad de una canción.

- `speechiness`: La presencia de palabra hablada en una canción es muy importante pues la gran mayoría de canciones (por no decir todas) que están en los rankings de popularidad suelen ser todas con letra.

- `instrumentalness`: La predominandia de la instrumentación sobre la voz pordría influir de la misma forma que la anterior.

- `duration_ms`: como hemos visto antes esta variable podria estar relacionada con la popularidad

- `liveness`: el porcentaje de una canción que se grabó en vivo o en estudio influirá en la popularidad.

- `acousticness`: la calidad acústica de la música es algo que tambien tendra relación.

- `loudness`: pensamos que el nivel de decibelios al que fue grabada la canción importará para la popularidad.

- `danceability`: La capacidad de una canción para ser baildad podría ser una factor importante.


Y para los predictores categóricos:

- `mode`: Si la canción está en modo mayor o menos podría influir en la percepción emocional y, por tanto, en su popularidad.

- `is_explicit`: La presencia de lenguaje explícito podría atraet a ciertos públicos y afectar. Por ejemplo, muchas canciones muy populares latinoamericanas tienen un alto porcentaje de palabras sexuales y escenarios explícitos y, a veces, cuan más explícito es más repercusión tiene. Por otra parte, canciones con un lenguaje explícito de violencia no suelen ser populares por motivos obvios.

- `key`: pensamos que la escala en la que está compuesta podrá afectar a la popularidad.

**3. Relacionados con `popularity`.**

Pensamos que las variables que más relación tienen con la popularidad son los puestos que tiene una canción diariamente y semanal y sus movimientos entre los puestos. `daily_rank`, `daily_movement` y `weekly_movement`.


**4. No relacionados.**

- `artists`: El artista podría ser un factor importante pues artitas más reconocidos tienen más propabilidad de producir canciones populares. Pero, no nos servira en nuestro estudio ya que estamos planteando hacer un reconocimiento para canciones nuevas que no tienen por que ser de artistas conocidos, por eso no nos va a aportar nada en el modelo que vamos a entrenar.

- `spotify_id`: no tiene relación porque es simplemente una forma de identificar la canción.

- `name`: creemos que el nombre de la canción no tendrá relevancia porque muchas de las canciones que más escuchamos en nuestro día a día porque se han hecho ``virales'' gracias a las redes sociales no conocemos sus nombres en un principio. 

- `country`: la ubicación geográfica del origen de la canción no tiene una correlación evidente con su popularidad ya que la mayoría de canciones que escuchamos que son populares no sabemos cuál es su origen o no nos interesa para porder disfrutarla.
 
- `album_name`: muchas de las canciones no más populares no salen ni en un álbum y en general, la gente no se fija en el álbum en sí al que pertenece una canción, simplemente en la canción si les gusta. 

# Apartado B
## Preparación de datos

Para empezar vamos a **eliminar la variable X**, ya que creemos que es una variable nula que se ha colado en la lectura del csv, después vamos a pasar a variables categóricas key y mode ya que actualmente se consideran como numéricas. Y convertiremos las clases `album_release_date` y `snapshot_date` en fechas, en lugar de cadenas para despues poder tratar con ellas.

```{r}
spotify = spotify[,-1]

spotify$mode = factor(spotify$mode)
spotify$key = factor(spotify$key)
spotify$time_signature = factor(spotify$time_signature)

spotify$album_release_date = as.Date(spotify$album_release_date)
spotify$snapshot_date = as.Date(spotify$snapshot_date)

```

A continuación vamos a mirar los **NA's** que presentan nuestras variables.
```{r}
colSums(is.na(spotify))
```

Después de haber mirado un poco por encima el dataset, sabemos que los 21 valores nulos que se muestran con `name` y `artists` son los mismos, al igual que los 22 de `album_release_date` y `album_name`. Además 21 de ellos coinciden como nulos con `name` y `album_name`. 

Aquí podemos ver la cantidad de nulos que coinciden con `name` y `artists`

```{r}
table(is.na(spotify$name), is.na(spotify$artists))
```

Aquí vemos la cantidad de nulos que coinciden con `album_release_date` y `album_name` 

```{r}
table(is.na(spotify$album_release_date), is.na(spotify$album_name))
```

y aquí la cantidad de nulos que coinciden con `name`y `album_release_date`

```{r}
table(is.na(spotify$name), is.na(spotify$album_name))
```
Lo que vamos a hacer es eliminar los 22 valores nulos de estas distintas filas, ya que consideramos que son pocos los datos de los que vamos a prescindir.

```{r}
spotify <- spotify[complete.cases(spotify$album_release_date), ]

colSums(is.na(spotify))
```
Ahora podemos ver que solo quedan 1452 nulos en la columna `country` del dataset. La estrategia que vamos a utilizar es omitir estas filas también, ya que contando actualmente con 105647 datos, creemos que podemos prescindir de estos 1452 nulos, dejándonos así con 104195 valores para nuestro trabajo de investigación.

```{r}
table(is.na(spotify$country))
spotify <- spotify[complete.cases(spotify$country), ]
```
A continuación, vamos a ver si tenemos **outliers** y en caso de verlos, los eliminaremos ya que queremos trabajar con los datos más representativos y cercanos entre sí, dejando así un mejor dataset para la predicción.

```{r}
analysisContinuas= spotify[ , c("popularity", "duration_ms", "danceability","energy", "loudness", "speechiness", "acousticness", "liveness", "instrumentalness", "valence", "tempo")]
mymelt=melt(analysisContinuas, id.vars=1, value.name="FeatureValue", variable.name="Feature")
 

unique_features <- unique(mymelt$Feature)
num_columns <- 5
num_rows <- ceiling(length(unique_features) / num_columns)
plots_list <- list()

# Tamaño total de la cuadrícula
total_width <- 15
total_height <- 20
single_plot_width <- total_width / num_columns
single_plot_height <- total_height / num_rows

# Itera a través de cada característica
for (i in seq_along(unique_features)) {
  subset_data <- mymelt[mymelt$Feature == unique_features[i], ]
   current_color <- colorspie[(i - 1) %% length(colorspie) + 1]
  
  # Crea el gráfico con ggplot usando los datos filtrados
  plot <- ggplot(data=subset_data, aes(x=Feature, y=FeatureValue, color=Feature, fill=Feature)) +
    geom_boxplot(alpha=0.6) +
    scale_fill_manual(values = current_color) +
    scale_color_manual(values = current_color) +
    ggtitle(paste(unique_features[i])) +
    theme_minimal() + 
    theme(legend.position="none",
          axis.title.x = element_blank(),  # Oculta la etiqueta del eje x
          axis.title.y = element_blank())
  
  # Agrega el gráfico a la lista
  plots_list[[i]] <- plot
  
  summary(mymelt)
}

# Organiza los gráficos en una cuadrícula y visualízalos
grid.arrange(grobs = plots_list, ncol = num_columns, widths = rep(single_plot_width, num_columns), heights = rep(single_plot_height, num_rows))

```

Un dato será *outlier* si se encuentra más allá de 3/2 del rango de intercuartil
```{r}
analysisContinuas= spotify[ , c( "duration_ms", "danceability","energy", "loudness", "speechiness", "acousticness", "liveness", "instrumentalness", "valence", "tempo")]

iqr_values <- apply(analysisContinuas, 2, function(x) {
  q1 <- quantile(x, 0.25)
  q3 <- quantile(x, 0.75)
  iqr <- q3 - q1
  limite_inferior <- q1 - 1.5 * iqr
  limite_superior <- q3 + 1.5 * iqr
  
  outliers_count <- sum(x < limite_inferior | x > limite_superior)
  
  return(list(Q1 = q1, Q3 = q3, IQR = iqr, LimiteInferior = limite_inferior, LimiteSuperior = limite_superior, Outliers = outliers_count))
})

for (i in seq_along(iqr_values)) {
  cat("Variable:", names(iqr_values)[i], "\n")
  cat("  Primer cuartil (Q1):", iqr_values[[i]]$Q1, "\n")
  cat("  Tercer cuartil (Q3):", iqr_values[[i]]$Q3, "\n")
  cat("  IQR:", iqr_values[[i]]$IQR, "\n")
  cat("  Límite inferior:", iqr_values[[i]]$LimiteInferior, "\n")
  cat("  Límite superior:", iqr_values[[i]]$LimiteSuperior, "\n")
  cat("  Número de outliers", iqr_values[[i]]$Outliers, "\n")
  cat("\n\n")
}
```

A pesar de ver una gran cantidad de datos outliers al hacer el cálculo teórico, creemos que no son datos que haya que borrar porque hay muchos juntos como ocurre en la gráfica con `instrumentalness`, que por la representación se ve que no hay ningún punto de datos que destaque por estar muy lejano al resto. 

Por otra parte, apoyándonos en los datos visuales de la gráfica y en los que acabamos de obtener, vamos a eliminar algunos valores de: `duration_ms`, `loudness` y `speechiness`.

```{r}
spotifyEliminacion <- spotify
# Marcamos los datos que eliminaremos de duration_ms
spotifyEliminacion$duration_delete <- if_else(spotifyEliminacion$duration_ms > 570000, TRUE, FALSE)
sum(spotifyEliminacion$duration_ms > 570000)
# Marcamos los datos de loudness
spotifyEliminacion$loudness_delete <- if_else(spotifyEliminacion$loudness > 0 | spotifyEliminacion$loudness< -25, TRUE, FALSE)
sum(spotifyEliminacion$loudness< -25 | spotifyEliminacion$loudness > 0)
# Marcamos los datos de speechiness
spotifyEliminacion$speechiness_delete <- if_else(spotifyEliminacion$speechiness > 0.7, TRUE, FALSE)
sum(spotifyEliminacion$speechiness > 0.7)

# Eliminamos estas filas
spotifyEliminacion <- spotifyEliminacion %>%
  filter(!(duration_delete | loudness_delete | speechiness_delete))
spotify <- spotifyEliminacion[, 1:25]

rm(spotifyEliminacion); rm(subset_data); 
```


**Respóndase a las siguientes preguntas en relación a la preparación de datos.**

\* **¿Qué predictores habría que normalizar? ¿Por qué? ¿Cuál sería la estrategia de normalización en cada caso?**

Los predictores que habría que normalizar son principalmente las características de las canción, para ello se podría utilizar el método **min-max** o la estandarización.
```{r}
songFeatures <-  c('danceability', 'energy', 'loudness', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'duration_ms')
```

Normalizar estas características puede ayudar a mejorar convergencia y rendimiento del modelo. Sobretodo si nos encontramos con magnitudes distintas como es por ejemplo duration_ms con respecto a danceability. Así la influencia de estas características en futuros modelos, como el de deep learning será similar y no tendrán tanto peso aquellas con magnitudes tan grandes.

```{r}
spotiNormalizado = spotify
min_max_normalize <- function(x) {
  (x - min(x)) / (max(x) - min(x)) * 2 - 1
}
spotiNormalizado[, songFeatures] <- lapply(spotiNormalizado[, songFeatures], min_max_normalize)
```

Además, creemos que sería interesante escalar debido al uso que le vamos a dar más adelante variables como `daily_movement`, `weekly_movement` y, como `daily_rank` tiene relación con las otras también la vamos a escalar.

```{r}
masDatos <- c('daily_movement', 'weekly_movement', 'daily_rank') 

spotiNormalizado[, masDatos] <- lapply(spotiNormalizado[, masDatos  ], min_max_normalize)
```

También vamos a comprobarlo utilizando el escalado de **z-score** pensando de cara a la próxima parte de la práctica y sabiendo de la existencia de valores negativos, creemos que es mejor hacerlo mediante el z-score. Para ello vamos a utilizar la función `scale` disponible en R.

```{r}
spotiNormalizadoZScore = spotify

songFeaturestoNorm = c('danceability', 'energy', 'loudness', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'duration_ms', 'daily_movement', 'weekly_movement', 'daily_rank')

spotiNormalizadoZScore[, songFeaturestoNorm] <- scale(spotiNormalizadoZScore[, songFeaturestoNorm],center = TRUE, scale = TRUE)
```


\* **¿Podría ser interesante transformar algún atributo o grupos de atributos en uno nuevo? ¿Por qué?**

Sí, lo que vamos a hacer es combinar las variables `album_release_date` y `snapshot_date` dando lugar a `diferencia_dias` y añadir los atributos `between_week_prev_popularity` y `day_prev_popularity` para tener guardados los datos de la popularidad previa, aprovechando así la secuencialidad.

Con `diferencia_dias` vamos a tener en cuenta los días que hay desde que se publica una canción hasta que esta obtiene una nueva posición en el ranking, la forma en la que podemos hacer esto es restar `snapshot_date` con `album_release_date` y tener así un registro del número de **días que una canción tardó en hacerse popular**, como la fecha de salida de una canción puede ser anterior a la salida de un álbum pondremos como 0 aquellas canciones que tienen como diferencia de fechas un valor negativo.

```{r}
diferencia_dias = as.numeric(spotify$snapshot_date - spotify$album_release_date)

spotify$diferencia_dias = diferencia_dias
spotify$diferencia_dias = ifelse(spotify$diferencia_dias < 0, 0, spotify$diferencia_dias)
```

Ahora vamos a calcular la **popularidad previa** de canciones en un conjunto de datos.

```{r secuencial}
spotify <- spotify %>%
  group_by(spotify_id,country) %>%
  arrange(snapshot_date) %>%
  mutate(between_week_prev_popularity = if_else(row_number() == 1, popularity, if_else((snapshot_date - lag(snapshot_date)>1 & (snapshot_date - lag(snapshot_date)<=7)) , lag(popularity), 0)))

spotify <- spotify %>%
  group_by(spotify_id,country) %>%
  arrange(snapshot_date) %>%
  mutate(day_prev_popularity = if_else(row_number() == 1, 0, if_else(snapshot_date - lag(snapshot_date) == 1, lag(popularity), 0)))


```

Primero organizamos la información por identificador y país, asegurándose de que los registros estén ordenados; luego, para cada canción se determina la popularidad que tenía en fechas anteriores, considerando únicamente aquellas con una diferencia de 1 a 7 días respecto a la fecha actual. El resultado es una nueva columna llamada `between_week_prev_popularity`, que refleja la popularidad previa de cada canción en el tiempo. Tambien se hace el mismo proceso para solamente el día anterior. Para la primera aparición por lista de cada canción se asigna su propia popularidad porque de no ser así nos saldria un valor NA.


También podríamos considerar la creación de una nueva varibale que represente la rapidez con la que una canción se vuelve popular. Por ejemplo, podríamos crear una variable `velocidad_popularidad` que sea el inverso de la diferencia de días, de manera que canciones que se vuelven populares rápidamente tengan valores más altos en esta nueva variable.

```{r}
epsilon <- 1e-10
# Calcular velocidad_popularidad con epsilon para evitar divisiones entre 0
spotify$velocidad_popularidad <-  1 / (spotify$diferencia_dias + epsilon)
```

\* **¿Cómo podría aprovecharse el carácter secuencial de los datos?**

El carácter secuancial de los datos podría aprovechase al considerar la creación de variables que capturen tendencias a lo largo del tiempo. Por ejemplo, un poco más arriba hemos creado una variable `prev_popularity` gracias a que las fechas son secuenciales y podemos acceder a la popularidad a lo largo de los días. De esta forma podemos analizar cómo cambia la popularidad de una canción a lo largo de la semana anterior, proporcionando información valiosa para entender patrones y tendencias en el comportamiento de reproducción de las canciones en la plataforma.


Antes de empezar el apartado C, vamos a eliminar finalmente los atributos que creemos que no nos van a ser de utilidad para realizar nuestros modelos. Para ello primero vamos a hacer un repaso con los pasos seguidos anteriormente:
 - Se eliminaron valores nulos, para poder hacer agrupaciones sin preocuparnos de los NA'S
 - Se eliminaron "outliers", aunque los eliminados fueron nuestra decisión, ya que vimos que había demasiados datos considerados outliers en distintos valores fuera del IQR que nos parecian representativos y necesarios. 



 

Hasta ahora no hemos hecho nada más que añadir columnas, pero sabemos de antemano que no todas ellas nos van a ser de utilidad para entrenar nuestro modelo. Sin embargo, no las hemos eliminado anteriormente para hacer la limpieza de datos pero ahora procedemos a quitar las columnas `spotify_id`, `name`, `artists`, `album_name`, `album_release_date`   

```{r}
eliminar = c("spotify_id", "name", "artists", "album_name", "album_release_date")
```


Anteriormente hemos agrupado los argumentos `album_release_date` y `snapshot_date` en la variable que recoge la diferencia de días. Por lo que ahora también consideramos oportuno quitar la variable `snapshot_date` ya que ya tenemos en el dataset el número de días que la canción ha tardado en tener la respectiva `popularity`.


```{r}
eliminar = c("spotify_id", "name", "artists", "album_name", "album_release_date","snapshot_date")
```


Cómo explicábamos antes, la variable country no nos va a ser de utilidad a determinar si una canción va a ser popular o no. Por otro lado somos conscientes de que el país si que afectaría a que tipo de canciones se vuelven o no populares, pero al igual que otros atributos como el artista (que ya hemos eliminado previamente). Como el objetivo es dada una canción saber si esta se va a hacer famosa o no, no vamos a tener en cuenta el país o continente.

```{r}
eliminar = c("spotify_id", "name", "artists", "album_name", "album_release_date","snapshot_date", "country")
```

Hasta ahora hemos borrado los parámetros que nos parecían más evidentes pero pensando en la resolución del problema, nosotras también llegamos a la conclusión de que los parámetros `daily_movement`, `daily_rank` y `weekly_movement` a pesar de que nos aportarán algo y sabemos que están relacionados con la popularidad, no nos ayudarán a determinar si una canción cualquiera se va a hacer famosa (al igual que con el parámetro `artists`). 

Hemos llegado a esta conclusión debido a que el pensamiento que tenemos nosotras al hacer esta práctica es que vamos a crear un proyecto para determinar si una cancion será popular o no, y estos tres parámetros nos dan información sobre canciones en la lista pero nada más. Para confirmar nuestras sospechas trabajaremos con un dataset conjunto que sí que tenga estos tres parámetros y después comprobaremos la precisión.

Nuestra hipótesis sobre estos parámetros es que sí tienen cierta importancia y que puestos más altos en el daily rank supondrán una mayor popularidad pero creemos que no nos servirá de mucho a la hora de determinar la posible popularidad de una canción futura.

```{r}
spotify = spotify[, !names(spotify) %in% eliminar]
spotiNormalizado = spotiNormalizado[, !names(spotiNormalizado) %in% eliminar]
spotiNormalizadoZScore = spotiNormalizadoZScore[, !names(spotiNormalizadoZScore) %in% eliminar]

nuevas_columnas = c('diferencia_dias', 'between_week_prev_popularity','day_prev_popularity', 'velocidad_popularidad')
spotiNormalizado[nuevas_columnas] <- spotify[, nuevas_columnas]
spotiNormalizadoZScore[nuevas_columnas] <- spotify[, nuevas_columnas]

spotifyNoMovements = spotify

eliminar = c("daily_rank", "daily_movement", "weekly_movement")
spotifyNoMovements = spotifyNoMovements[, !names(spotify) %in% eliminar]

spotifyNormNoMovements = spotiNormalizado
spotifyNormNoMovements = spotiNormalizado[,!names(spotiNormalizado) %in% eliminar ]

spotifyNormNoMovementsZScore = spotiNormalizadoZScore
spotifyNormNoMovementsZScore = spotiNormalizadoZScore[,!names(spotiNormalizado) %in% eliminar ]
```


```{r}
#SAVE POINT PARA CUANDO LA CAGO. BORRAR  Y LO DE ABAJO 
savePoint = spotify
```

creemos que saber de antemano la popularidad exacta de una canción va a ser muy complicado. Creemos que es mejor idea hacer una factor de la popularidad donde se adivine si esta va a ser muy popular (su valor de popularidad es de entre 90-100), si va a ser popular (su valor de popularidad es de entre 60-90) o si no va a ser muy popular (su valor de popularidad es de entre 30-60) o si apenas lo va a ser (0-30). Porque pensamos que el objetivo, es saber si la canción va a ser buena o no y preferimos abordar un problema de clasificación a un problema de regresión, ya que en caso de llevar a la realidad, creemos que interesaría más darle a conocer este dato a un número de popularidad más exacta, por lo que, si la otra idea no es abordable llevaremos a cabo una que trabaje con la variable `popularity`, factorizada, de la siguiente manera:

```{r, eval= false}
intervalos <- c(0, 30, 60, 90, 101)
spotify2 = spotify
spotify2$popularity <- cut(spotify2$popularity, breaks = intervalos, labels = c("nada popular", "poco popular", "algo popular", "hit"), include.lowest = TRUE, right = FALSE)
spotify2$popularity = as.factor(spotify2$popularity)
```


# Apartado C
## Random Forest
### Funcionamiento

**Explicar brevemente el tipo de modelo que genera el algoritmo, y cuál es la estrategia de dicho algoritmos para construir el modelo.**

El algoritmo **Random Forest** se utiliza para tareas de clasificaión y de regresión. Su estructura consiste en un conjunto de árboles de decisión, de ahí que se denomine ``bosque''. La estrategia principal del Random Forest se basa en la combinación de múltiples árboles de decisión mediante el siguiente proceso:

1. **Muestreo aleatorio de datos:** Se toma el conjunto de entrenamiento y se crean múltiples subconjuntos mediante muestreo aleatorio con reemplazo.

2. **Construcción de árbolres de decisión:** Cada subconjunto se utiliza para entrenar un árbol de decisión mediante un proceso recursivo de partición basado en la mejor característica.

3. **Valoración:** Se realiza la predicción para cada árbol y, en clasificación, se realiza una votación para determinar la clase final y en regresión, se promedian las predicciones.

La idea clave es combinar la información de múltiples árboles para reducir sobreajuste y mejorar la generalización.


### Requisitos
**Indicar si el algoritmo en cuestión tiene algún requisito en cuanto a si se han de preprocesar los datos (e.g. escalado, imputación de valores nulos, etc.) y cómo. Explicar cómo se ha tenido en cuenta estos requisitos a la hora de generar los datos de training específicos para este algoritmo.**

Random Forest no tiene requisitos estrictos en cuanto al preprocesamiento de datos. Sin embargo, cambios que hemos hecho en los datos ayudarán al rendimiento como puede ser la eliminación de datos no relevantes y el manejo de los valores nulos.

Tal y como vimos en clase vamos a utilizar la función ranger, debido a su rapidez en la implementación de bosques aleatorios.
### Descripción de hiperparámetros
**Identificar y explicar cada uno de sus parámetros de configuración.**

Los hiperparámetros de configuración son los siguientes:

```{r}
rangerInfo = getModelInfo("ranger")
rangerInfo = rangerInfo$ranger
rangerInfo$parameters
```
Aqui podemos ver los parametros `mtry`, `splitrule`, `min.node.size`.

Donde `mtry` es el número de variables a considerar en cada división del árbol, hemos leido que se suele probar con la raiz cuadrada del número de variables, por lo que nosotras vamos a probar con valores que van de 4 a 6.
Por otro lado `splitrule` es la regla que se utiliza para dividir cada nodo. Al tratarse de un problema de regresión, estamos probando con variance y con extratree.
Y por ultimo `min.node.size` que es el numero de ejemplos que debe haber como minimo en cada nodo.
 En nuestro caso estaremos probando con 50,100 y 150 
 
### Grid Hiperparámetros
**Detallar una estrategia para la generación del grid de valores para hiperparámetros a usar.**

A continuacion se puede ver como hemos generado un grid, implementando lo que comentamos en el apartado anterior y más adelante como hemos probado con distintos números de árboles; para los valores 200,300,400 y 500. De esta forma veremos si el número de árboles es significativo.

```{r}
mygrid <- expand.grid(
  mtry = c(4, 5, 6),
  splitrule = c("variance", "extratrees"),
  min.node.size = c(50, 100, 150))

fitControl <- trainControl(## 10-fold CV
                           method = "cv",
                           number = 10)
```


En el primer chunk donde entrenamos un modelo, se puede ver además comentado, que antes de ejecutar el codigo con todos los datos, se hizo también para un porcentaje de datos de la muestra. En nuestro caso fue del 30%. Al encontrar resultados significativos con el grid pensado, hemos decidido seguir adelante con él y más abajo se contrastaran los resultados y se probara que al menos una de las configuraciones nos produce unos resultados aceptables. 

```{r}
set.seed(123)
inTraining <- createDataPartition(spotify$popularity, times=1,p = .80, list = FALSE)
training <- spotify[ inTraining,]
testing  <- spotify[-inTraining,]
```



```{r rf200trees, eval=FALSE}
set.seed(44)
#porcentaje_datos <- 0.30
#tamanio_muestra <- round(nrow(spotify) * porcentaje_datos)
#spotify = spotify[sample(nrow(spotify), tamanio_muestra), ]

#set.seed(126)
#inTraining <- createDataPartition(spotify$popularity, times=1,p = .80, list = FALSE)
#training <- spotify[ inTraining,]
#testing  <- spotify[-inTraining,]



rf_200t <- train(popularity ~ ., data = training, 
                 method = "ranger", 
                 trControl = fitControl,
                 num.trees = 200,
                 tuneGrid=mygrid)

saveRDS(object= rf_200t, file = "numTrees200.rds")
```

```{r rf300trees, eval= FALSE}
#set.seed(126)
#inTraining <- createDataPartition(spotify$popularity, times=1,p = .80, list = FALSE)
#training <- spotify[ inTraining,]
#testing  <- spotify[-inTraining,]


rf_300t <- train(popularity ~ ., data = training, 
                 method = "ranger", 
                 trControl = fitControl,
                 num.trees = 300,
                 tuneGrid=mygrid)

saveRDS(object= rf_300t, file = "numTrees300.rds")
```

```{r rf400trees, eval = FALSE}
#set.seed(126)
#inTraining <- createDataPartition(spotify$popularity, times=1,p = .80, list = FALSE)
#training <- spotify[ inTraining,]
#testing  <- spotify[-inTraining,]

rf_400t <- train(popularity ~ ., data = training, 
                 method = "ranger", 
                 trControl = fitControl,
                 num.trees = 400,
                 tuneGrid=mygrid)

saveRDS(object= rf_400t, file = "numTrees400.rds")
```

```{r rf500trees, eval = FALSE}
#set.seed(126)
#inTraining <- createDataPartition(spotify$popularity, times=1,p = .80, list = FALSE)
#training <- spotify[ inTraining,]
#testing  <- spotify[-inTraining,]


rf_500t <- train(popularity ~ ., data = training, 
                 method = "ranger", 
                 trControl = fitControl,
                 num.trees = 500,
                 tuneGrid=mygrid)

saveRDS(object= rf_500t, file = "numTrees500.rds")
```

```{r, eval=FALSE}
rf_200t = readRDS("numTrees200.rds")
rf_300t = readRDS("numTrees300.rds")
rf_400t = readRDS("numTrees400.rds")
rf_500t = readRDS("numTrees500.rds")

resultados <- data.frame(
  "NumArboles" = c("200", "300", "400", "500"),
  "Splitrule" = c(rf_200t$bestTune$splitrule, rf_300t$bestTune$splitrule, rf_400t$bestTune$splitrule, rf_500t$bestTune$splitrule),
  "Min node size" = c(rf_200t$bestTune$min.node.size, rf_300t$bestTune$min.node.size, rf_400t$bestTune$min.node.size, rf_500t$bestTune$min.node.size),
  "Mtry" = c(rf_200t$bestTune$mtry, rf_300t$bestTune$mtry, rf_400t$bestTune$mtry, rf_500t$bestTune$mtry)
)
resultados
```

Podemos para todas las opciones de número de árboles que hemos contemplado obtenemos la misma configuración.

```{r, eval=FALSE}
# Función para calcular MAE y RMSE
calcular_metricas <- function(modelo) {
  predicciones <- predict(modelo, newdata = testing)
  mae <- mae(predicciones, testing$popularity)
  rmse <- rmse(predicciones, testing$popularity)
  return(c(MAE = mae, RMSE = rmse))
}

# Comparación MAE y RMSE
comparacion <- data.frame(
  rf_200t = calcular_metricas(rf_200t),
  rf_300t = calcular_metricas(rf_300t),
  rf_400t = calcular_metricas(rf_400t),
  rf_500t = calcular_metricas(rf_500t)
)
comparacion
```


Para este dataset, en lugar de ejecutarlo con distintas posibilidades, como en todos los anteriores nos ha dado la misma combinación, para este solo vamos a utilizar esa en concreto con un número de 300 arboles. Recordamos que este dataset, no tiene los atributos de `daily_rank`, `daily_movement`, `weekly_movement`.

```{r, eval =FALSE}
#spotify = spotifyNoMovements
inTraining <- createDataPartition(spotifyNoMovements$popularity, times=1,p = .80, list = FALSE)
training <- spotifyNoMovements[ inTraining,]
fitControl <- trainControl(## 10-fold CV
                           method = "cv",
                           number = 10)

mygrid <- expand.grid(
  mtry = 6,
  splitrule = c("variance"),
  min.node.size = 50)
mygrid

fitControl <- trainControl(## 10-fold CV
                           method = "cv",
                           number = 10)

spotifyrf <-train (popularity ~ ., data = training,
                   method = "ranger",
                   trControl = fitControl,
                   num.trees = 300,
                   tuneGrid=mygrid)

saveRDS(object= spotifyrf, file = "spotifyNoMovements.rds")
```

```{r}
rfNoMov = readRDS("spotifyNoMovements.rds")
```



```{r}
predicciones <- predict(rfNoMov, newdata = testing)
mae <- mae(predicciones, testing$popularity)
rmse <- rmse(predicciones, testing$popularity)

mae
rmse
```
Como pensábamos, el modelo sin los valores de `daily_movement`, `daily_rank` y `weekly_movement` ha tenido unos resultados más bajos para el RMSE y el MAE, lo que nos inidica que tiene un mejor rendimiento.

Tras ver los resultados del apartado anterior, podemos describir los hiperpárametros escogidos del modelo:

- *Splitrule:* Este parámetro determina la regla utilizada para dividir los nodos en los árboles de decisión. En este caso, se ha elegido la opción `variance.` La regla de división basada en la varianza busca maximizar la homogeneidad de las variables en los nodos del árbol.

- *Min.node.size:*  Este hiperparámetro establece el número mínimo de observaciones requeridas en un nodo terminal del árbol. En el contexto de Random Forest, un valor de 50 para `min.node.size` significa que un nodo terminal debe contener al menos 50 observaciones para considerarse válido. Este valor puede ayudar a controlar la complejidad del árbol y evitar sobreajustes.

- *Mtry:* Este parámetro controla el número de variables aleatorias consideradas en cada división de nodo. Un valor de 6 para `mtry` implica que, en cada división, el algoritmo seleccionará aleatoriamente 6 variables predictoras del conjunto total de variables.

La elección de estos valores específicos para los hiperparámetros se basa en los resultados obtenidos durante el análisis en el apartado anterior. Observamos que esta combinación en particular tuvo un el mejor rendimiento según el RMSE y MAE.

### Resultados
**Describir los resultados del algoritmo.**

Con las conclusiones anteriores, el que pensamos que es el mejor modelo es `rfNoMov`. Como hemos comentado, la configuración de este modelo es:

- Splitrule: variance
- Min.node.size: 50
- Mtry: 6

El modelo se entrenó con *300 árboles*, y los resultados fueron los siguientes:

- MAE (Error Absoluto Medio): 0.5488207
- RMSE (Error Cuadrático Medio): 1.989452

Estos resultados indican que el modelo tiene una capacidad sustancial para hacer predicciones precisas sobre la popularidad de las canciones en función de las variables disponibles. En comparación con los modelos anteriores que incluían las variables excluidas, este modelo reducido logró un rendimiento aún mejor, lo que respalda la decisión de prescindir de esas características específicas en este contexto.

```{r}
rfNoMov
```


## Deep learning
### Funcionamiento
**Explicar brevemente el tipo de modelo que genera el algoritmo, y cuál es la estrategia de dicho algoritmos para construir el modelo.**

El **Deep Learning** se utiliza en redes neuronales profundas para modelar y resolver problemas complejos. Una red neuronal profunda consta de múltiples capas, incluyendo capas de entrada, capas ocultas y capas de salida por las que van pasando los datos. La estrategia es la siguiente:

1. **Propagación hacia adelante (Forward Propagation):** Los datos se introducen en la red y se propagan hacia adelante a través de las capas, generando una predicción.

2. **Cálculo de pérdida:** Se compara la predicción con las etiquetas reales para calcular la pérdida.

3. **Retropropagación (Backward Propagation):** Se propaga hacia atrás la pérdida a través de la red, ajustando los pesos de las conexiones para minimizar la pérdida.

4. **Optimización:** Se utiliza un algoritmo de optimización *(como Gradiente Descendente)* para actualizar los pesos y minimizar la pérdida.

Este proceso se repite en varias épocas (iteraciones a través del conjunto de datos) durante el entrenamiento.

### Requisitos
**Indicar si el algoritmo en cuestión tiene algún requisito en cuanto a si se han de preprocesar los datos (e.g. escalado, imputación de valores nulos, etc.) y cómo. Explicar cómo se ha tenido en cuenta estos requisitos a la hora de generar los datos de training específicos para este algoritmo.**

Los requisitos para el Deep Learning incluyen:

- Normalización de variables: para que tengan una media cercana a cero y una desviación estándar similar.

- Manejo de valores nulos: los datos deben estar limpios de valores nulos antes del entrenamiento.

- Codificación de variables categóricas: las variables categóricas deben codificarse adecuadamente para ser utilizadas en la red neuronal.

Aunque hemos tenido en cuenta estos requisitios en la preparación de datos, hemos modificado un podo el conjunto de datos por lo que vamos a terminar de arreglarlo para poder utilizarlo.

```{r}
restantesNormal = c('velocidad_popularidad', 'diferencia_dias', 'between_week_prev_popularity', 'day_prev_popularity')
spotiNormalizado[, restantesNormal] <- lapply(spotiNormalizado[, restantesNormal], min_max_normalize)
spotifyNormNoMovements[, restantesNormal] <- lapply(spotifyNormNoMovements[, restantesNormal], min_max_normalize)
spotiNormalizadoZScore[, restantesNormal] = scale(spotiNormalizadoZScore[, restantesNormal],center = TRUE, scale = TRUE)
spotifyNormNoMovementsZScore[, restantesNormal] = scale(spotifyNormNoMovementsZScore[, restantesNormal],center = TRUE, scale = TRUE)
```
A continuacion tenemos que tratar tambien con las variables categóricas `key`, `mode` , `time_signature`, `is_exlicit`. Para ello vamos a utilizar la tecnica one-Hot-Encoding. Que nos permitira representar numéricamente variables categóricas y manejar variables categóricas con múltiples categorías, estas variables no las tendremos que normalizar, ya que hemos generado una columna nueva para cada posible valor de las columnas `key`, `mode`y `time_signature`, poniendo como valor 1 si coincide el valor original con el nombre de la columna.

```{r}
savePointNNM = spotifyNormNoMovements
savePointNorm = spotiNormalizado
```



key_values <- c(0,1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11)

for (key_value in key_values) {
  column_name <- paste0("key_", key_value)
  spotiNormalizado[column_name] <- as.integer(spotiNormalizado$key == key_value)
  spotifyNormNoMovements[column_name] <- as.integer(spotifyNormNoMovements$key == key_value)
  spotiNormalizadoZScore[column_name] <- as.integer(spotiNormalizadoZScore$key == key_value)
  spotifyNormNoMovementsZScore[column_name] <- as.integer(spotifyNormNoMovementsZScore$key == key_value)
}

time_signatures <- c(1,3,4,5)

for (time_signature_v in time_signatures) {
  column_name <- paste0("time_signature_", time_signature_v)
  spotiNormalizado[column_name] <- as.integer(spotiNormalizado$time_signature == time_signature_v)
  spotifyNormNoMovements[column_name] <- as.integer(spotifyNormNoMovements$time_signature == time_signature_v)
  spotiNormalizadoZScore[column_name] <- as.integer(spotiNormalizadoZScore$time_signature == time_signature_v)
  spotifyNormNoMovementsZScore[column_name] <- as.integer(spotifyNormNoMovementsZScore$time_signature == time_signature_v)
}

spotiNormalizado$is_explicit = ifelse(spotiNormalizado$is_explicit, 1, 0)
spotifyNormNoMovements$is_explicit = ifelse(spotifyNormNoMovements$is_explicit, 1, 0)
spotiNormalizadoZScore$is_explicit = ifelse(spotiNormalizadoZScore$is_explicit, 1, 0)
spotifyNormNoMovementsZScore$is_explicit = ifelse(spotifyNormNoMovementsZScore$is_explicit, 1, 0)


modes <- c(0,1)

for (mode_value in modes) {
  column_name <- paste0("mode_", mode_value)
  spotiNormalizado[column_name] <- as.integer(spotiNormalizado$mode == mode_value)
  spotifyNormNoMovements[column_name] <- as.integer(spotifyNormNoMovements$mode == mode_value)
  spotiNormalizadoZScore[column_name] <- as.integer(spotiNormalizadoZScore$mode == mode_value)
  spotifyNormNoMovementsZScore[column_name] <- as.integer(spotifyNormNoMovementsZScore$mode == mode_value)

}

eliminar = c('mode', 'key', 'is_explicit', 'time_signature')
spotiNormalizado = spotiNormalizado[, !names(spotiNormalizado) %in% eliminar]
spotifyNormNoMovements = spotifyNormNoMovements[, !names(spotifyNormNoMovements) %in% eliminar]
spotiNormalizadoZScore = spotiNormalizadoZScore[, !names(spotiNormalizadoZScore) %in% eliminar]
spotifyNormNoMovementsZScore = spotifyNormNoMovementsZScore[, !names(spotifyNormNoMovementsZScore) %in% eliminar]

```

### Descripción de hiperparámetros
**Identificar y explicar cada uno de sus parámetros de configuración.**
Se consideran para la resolución del modelo `mlpKerasDropout` y `mlpKerasDecay`, creemos que los modelos de los costes no son los más acertados, debido a que no nos interesa tener como hiperparametro costes para el modelo que estamos resolviendo
mlpDropoutInfo = getModelInfo("mlpKerasDropout")

mlpDecayInfo = getModelInfo("mlpKerasDecay")
mlpHiper = data.frame(mlpDropoutInfo$mlpKerasDropout$parameters, mlpDecayInfo$mlpKerasDecay$parameters)
mlpHiper
```

Podemos ver como ambas funciones tienen en común los parametros `size`, `batch_size`, `lr`, `rho`, `decay`, `activation`
//TODO TO DO
 - size: Número de neuronas en una capa.
 - batch_size: Cantidad de datos utilizados en cada actualización del modelo durante el entrenamiento.
 - lr (tasa de aprendizaje): Controla el tamaño de los pasos durante la optimización.
 - rho: Parámetro asociado con métodos de optimización específicos (como en RMSprop).
 - decay: Decaimiento de la tasa de aprendizaje a lo largo del tiempo.
 - activation: Función de activación aplicada a las salidas de las unidades en una capa.
 
 por otro lado tenemos `dropout` que pertenece a mlpKerasDropout y `lambda` que pertenece a mlpKerasDecay
 -`dropout` La tasa de Dropout es un hiperparámetro que controla la proporción de unidades (neuronas) en una capa que se "apagan" o se excluyen aleatoriamente durante cada paso de entrenamiento. Esto significa que, durante el entrenamiento, un porcentaje de las conexiones en la red se desactivan temporalmente, lo que ayuda a prevenir el sobreajuste y mejora la generalización del modelo.

 - `lambda`  El parámetro lambda se asocia con la regularización L2. La regularización L2 agrega un término a la función de pérdida del modelo que penaliza los pesos de las conexiones, evitando que tomen valores extremadamente grandes. Esto ayuda a prevenir el sobreajuste y a mejorar la robustez del modelo.

La prinicpal diferencia radica en:

Dropout está relacionado con la exclusión aleatoria de unidades durante el entrenamiento para evitar el sobreajuste. Es una técnica de regularización específica para las capas ocultas de la red.

Lambda en este contexto se asocia con la regularización L2, que penaliza los pesos de las conexiones. Es una técnica de regularización que afecta directamente a los parámetros del modelo.

Nosotras vamos a realizar experimentos para ambos para ver si resulta significativo utilizar Dropout o Decay

### Grid Hiperparámetros
**Detallar una estrategia para la generación del grid de valores para hiperparámetros a usar.**

set.seed(124)

inTraining <- createDataPartition(spotiNormalizado$popularity, times=1,p = .80, list = FALSE)
training <- spotiNormalizado[ inTraining,]
testing  <- spotiNormalizado[-inTraining,]

training2 <- spotifyNormNoMovements[ inTraining,]
testing2 <- spotifyNormNoMovements [-inTraining,]

paramgrid2 <- expand.grid(
  size = c(40,50), 
  dropout =c(0.1,0.3),
  batch_size = c(15,20),
  lr = c(0.01,0.02),
  rho = 0.91,
  decay = c(1e-6, 1e-5),
  activation = 'tanh'
)

# Definir el control del modelo
fitControl <- trainControl(
  method = "cv",  # Cross-validation
  number = 10,     # Número de folds
)
```

Este entrenamiento se ha hecho con 32 combinaciones distintas para el grid y ha conllevado una duración superior a 12 horas, por lo que para los siguientes modelos entrenados con `mlpKerasDropout`se va a mirar cuales han sido las mejores 5 combinaciones de los grids y se van a entrenar de esa manera.

```{r, eval=FALSE}

# Entrenar el modelo utilizando train()
modelo <- train(
  popularity ~ ., 
  data = training,
  method = "mlpKerasDropout",  # Puedes ajustar esto según el nombre del método que estás utilizando
  trControl = fitControl,
  tuneGrid = paramgrid2,
  epochs = 25
)

# Ver los resultados

saveRDS(object = modelo, file = "mlpNorm1Dropout.rds")

# Realizar predicciones
#predicciones <- predict(modelo, newdata = testing)
#mae <- mae(predicciones, testing$popularity)
#rmse <- rmse(predicciones, testing$popularity)

```

mlp1 = readRDS("mlpNorm1Dropout.rds")
mlp1
```
Vemos que las 5 mejores combinaciones tienen el mismo `size`, que es 40, el mismo `dropout`, que es 0.1, y para el `batch_size` hay 4 combinaciones con 15, y 1 con 20. El `lr` oscila tambien entre 0.01 y 0.02, y el decay entre 1e-5 y 1e-6 

```{r}
predicciones <- predict(mlp1, newdata = testing)
mae <- mae(predicciones, testing$popularity)
rmse <- rmse(predicciones, testing$popularity)
mae;rmse
```
Debido al gran tiempo de ejecución que nos ha consumido esta red neuronal vamos a resumir el grid como hemos dicho anteriormente para el entrenamiento posterior de modelos que utlicen Dropout. La creación del nuevo grid es la siguiente:

```{r}
gridDropOut <- expand.grid(
  size = 40, 
  dropout =0.1,
  batch_size = c(15,20),
  lr = c(0.01,0.02),
  rho = 0.91,
  decay = c(1e-6, 1e-5),
  activation = 'tanh'
)
```
Este grid solo tiene 8 combinaciones distintas.


```{r, eval=FALSE}

paramgrid2 <- expand.grid(
  size = c(40,50), 
  lambda =c(0.001,0.003),
  batch_size = c(15,20),
  lr = c(0.01,0.02),
  rho =0.91,
  decay = c(1e-6, 1e-5),
  activation = 'tanh'
)

# Entrenar el modelo utilizando train()
modelo <- train(
  popularity ~ ., 
  data = training,
  method = "mlpKerasDecay",  # Puedes ajustar esto según el nombre del método que estás utilizando
  trControl = fitControl,
  tuneGrid = paramgrid2,
  epochs = 25
)

# Ver los resultados

saveRDS(object = modelo, file = "mlpNorm1Decay.rds")

# Realizar predicciones
#predicciones <- predict(modelo, newdata = testing)
#mae <- mae(predicciones, testing$popularity)
#rmse <- rmse(predicciones, testing$popularity)
```


```{r, eval=FALSE}

paramgrid2 <- expand.grid(
  size = c(40,50), 
  dropout =c(0.1,0.3),
  batch_size = c(15,20),
  lr = c(0.01,0.02),
  rho =0.91,
  decay = c(1e-6, 1e-5),
  activation = 'tanh'
)

modelo <- train(
  popularity ~ ., 
  data = training2,
  method = "mlpKerasDropout",  # Puedes ajustar esto según el nombre del método que estás utilizando
  trControl = fitControl,
  tuneGrid = gridDropOut,
  epochs = 25
)

# Ver los resultados

saveRDS(object = modelo, file = "mlpNormNoMovDropout.rds")
```


```{r, eval=FALSE}
paramgrid2 <- expand.grid(
  size = c(40,50), 
  lambda =c(0.001,0.003),
  batch_size = c(15,20),
  lr = c(0.01,0.02),
  rho =0.91,
  decay = c(1e-6, 1e-5),
  activation = 'tanh'
)

# Entrenar el modelo utilizando train()
modelo <- train(
  popularity ~ ., 
  data = training2,
  method = "mlpKerasDecay",  # Puedes ajustar esto según el nombre del método que estás utilizando
  trControl = fitControl,
  tuneGrid = paramgrid2,
  epochs = 25
)

# Ver los resultados

saveRDS(object = modelo, file = "mlpNormNoMovDecay.rds")
```




#### Normalizado z-score

set.seed(125)
spotiNormalizado = spotiNormalizadoZScore
spotifyNormNoMovements = spotifyNormNoMovementsZScore

inTraining <- createDataPartition(spotiNormalizado$popularity, times=1,p = .80, list = FALSE)
training <- spotiNormalizado[ inTraining,]
testing  <- spotiNormalizado[-inTraining,]

training2 <- spotifyNormNoMovements[ inTraining,]
testing2 <- spotifyNormNoMovements [-inTraining,]


# Definir el control del modelo
fitControl <- trainControl(
  method = "cv",  # Cross-validation
  number = 10,     # Número de folds
)
```



# Entrenar el modelo utilizando train()
modelo <- train(
  popularity ~ ., 
  data = training,
  method = "mlpKerasDropout",  # Puedes ajustar esto según el nombre del método que estás utilizando
  trControl = fitControl,
  tuneGrid = gridDropOut,
  epochs = 25
)

# Ver los resultados

saveRDS(object = modelo, file = "mlpNorm2Dropout.rds")

# Realizar predicciones
#predicciones <- predict(modelo, newdata = testing)
#mae <- mae(predicciones, testing$popularity)
#rmse <- rmse(predicciones, testing$popularity)

```

```{r, eval=FALSE}

paramgrid2 <- expand.grid(
  size = c(40,50), 
  lambda =c(0.001,0.003),
  batch_size = c(15,20),
  lr = c(0.01,0.02),
  rho =0.91,
  decay = c(1e-6, 1e-5),
  activation = 'tanh'
)

# Entrenar el modelo utilizando train()
modelo <- train(
  popularity ~ ., 
  data = training,
  method = "mlpKerasDecay",  # Puedes ajustar esto según el nombre del método que estás utilizando
  trControl = fitControl,
  tuneGrid = paramgrid2,
  epochs = 25
)

# Ver los resultados

saveRDS(object = modelo, file = "mlpNorm2Decay.rds")

# Realizar predicciones
#predicciones <- predict(modelo, newdata = testing)
#mae <- mae(predicciones, testing$popularity)
#rmse <- rmse(predicciones, testing$popularity)
```


paramgrid2 <- expand.grid(
  size = c(40,50), 
  dropout =c(0.1,0.3),
  batch_size = c(15,20),
  lr = c(0.01,0.02),
  rho =0.91,
  decay = c(1e-6, 1e-5),
  activation = 'tanh'
)

modelo <- train(
  popularity ~ ., 
  data = training2,
  method = "mlpKerasDropout",  # Puedes ajustar esto según el nombre del método que estás utilizando
  trControl = fitControl,
  tuneGrid = gridDropOut,
  epochs = 25
)

# Ver los resultados

saveRDS(object = modelo, file = "mlpNormNoMov2Dropout.rds")
```


```{r, eval=FALSE}
paramgrid2 <- expand.grid(
  size = c(40,50), 
  lambda =c(0.001,0.003),
  batch_size = c(15,20),
  lr = c(0.01,0.02),
  rho = 0.91,
  decay = c(1e-6, 1e-5),
  activation = 'tanh'
)

# Entrenar el modelo utilizando train()
modelo <- train(
  popularity ~ ., 
  data = training2,
  method = "mlpKerasDecay",  # Puedes ajustar esto según el nombre del método que estás utilizando
  trControl = fitControl,
  tuneGrid = paramgrid2,
  epochs = 25
)

# Ver los resultados

saveRDS(object = modelo, file = "mlpNormNoMov2Decay.rds")
```

### Resultados
**Describir los resultados del algoritmo.**


## Cluestering
### Funcionamiento
**Explicar brevemente el tipo de modelo que genera el algoritmo, y cuál es la estrategia de dicho algoritmos para construir el modelo.**

El algoritmo de clustering se utiliza para agrupar datos similares entre sí en conjuntos llamados "clusters". Uno de los métodos más comunes es el k-means. Su estrategia es la siguiente:

1. **Inicialización:** Se seleccionan aleatoriamente los centroides iniciales para los k clusters.

2. **Asignación:** Cada punto de datos se asigna al cluster cuyo centroide es el más cercano.

3. **Actualización:** Se recalculan los centroides de los clusters basándose en los puntos de datos asignados.

4. **Iteración:** Se repiten los pasos 2 y 3 hasta que los centroides convergen o se alcanza un número máximo de iteraciones.

El resultado es un conjunto de clusters donde los puntos de datos dentro de cada cluster son más similares entre sí que con aquellos en otros clusters.

### Requisitos
**Indicar si el algoritmo en cuestión tiene algún requisito en cuanto a si se han de preprocesar los datos (e.g. escalado, imputación de valores nulos, etc.) y cómo. Explicar cómo se ha tenido en cuenta estos requisitos a la hora de generar los datos de training específicos para este algoritmo.**

Los requisitos para el clustering, especialmente para k-means, incluyen:

- Escalado de variables: Dado que el algoritmo de k-means se basa en distancias euclidianas, es importante escalar las variables para que tengan la misma influencia en el cálculo de las distancias. Esto ya lo hemos contemplado en la preparación de los datos.

- Manejo de valores nulos: Los valores nulos pueden afectar la calidad del clustering, por lo que es importante tratarlos antes del entrenamiento, lo cual hemos ya.


### Descripción de hiperparámetros
**Identificar y explicar cada uno de sus parámetros de configuración.**
Los hiperparámetros de configuración son los siguientes:

```{r}
knnInfo = getModelInfo("knn")
knnInfo = knnInfo$knn
knnInfo$parameters
```
Vemos que solo tenemos un parámetro, **k**, que es el número de vecinos más cercanos que se tienen en cuenta al realizar una predicción.

```{r, eval=FALSE}
set.seed(123)

# Definir las variables de entrada y salida
spotiKNN.Var.Salida.Usada <- c("popularity")
spotiKNN.Vars.Entrada.Usadas <- setdiff(names(spotiNormalizado), spotiKNN.Var.Salida.Usada)

# Crear una partición del 80% para entrenamiento y 20% para prueba
spotiKNN.Particion <- createDataPartition(spotiNormalizado[[spotiKNN.Var.Salida.Usada]], 
                                       p = 0.8, 
                                       list = FALSE,
                                       times = 1)

# Crear conjuntos de entrenamiento y prueba
spotiKNN.Datos.Entrenamiento <- spotiNormalizado[spotiKNN.Particion, ]
spotiKNN.Datos.Prueba <- spotiNormalizado[-spotiKNN.Particion, ]

# Usamos cross-validación 
fitControl <- trainControl(## 10-fold CV
                           method = "cv",
                           number = 10)
mygrid <- expand.grid(
  k = c(10, 50, 100, 200))

# Crear modelos utilizando el método train() de Caret
spotiKNN.modelo.knnReg <- train(popularity ~ ., 
                             data = spotiKNN.Datos.Entrenamiento, 
                             method = "knn", 
                             trControl = fitControl, 
                             tuneGrid = mygrid)
spotiKNN.modelo.knnReg
saveRDS(spotiKNN.modelo.knnReg, "knnReg.rds")
```


```{r, eval=FALSE}
knnReg_model = readRDS("knnReg.rds")
knnReg_model

predicciones <- predict(knnReg_model, newdata = spotiKNN.Datos.Prueba)
maeKnn <- MAE(predicciones, spotiKNN.Datos.Prueba$popularity)
rmseKnn <- RMSE(predicciones, spotiKNN.Datos.Prueba$popularity)

maeKnn; rmseKnn
```

Ahora vamos a probar con los datos normalizados pero sin las variables `daily_movement`, `daily_rank` y `weekly_movement`.

```{r, eval=FALSE}
set.seed(123)

# Definir las variables de entrada y salida
spotiKNN.Var.Salida.Usada <- c("popularity")
spotiKNN.Vars.Entrada.Usadas <- setdiff(names(spotifyNormNoMovements), spotiKNN.Var.Salida.Usada)

# Crear una partición del 80% para entrenamiento y 20% para prueba
spotiKNN.Particion <- createDataPartition(spotifyNormNoMovements[[spotiKNN.Var.Salida.Usada]], 
                                       p = 0.8, 
                                       list = FALSE,
                                       times = 1)

# Crear conjuntos de entrenamiento y prueba
spotiKNN.Datos.Entrenamiento <- spotifyNormNoMovements[spotiKNN.Particion, ]
spotiKNN.Datos.Prueba <- spotifyNormNoMovements[-spotiKNN.Particion, ]

# Usamos cross-validación 
fitControl <- trainControl(## 10-fold CV
                           method = "cv",
                           number = 10)
mygrid <- expand.grid(
  k = c(10, 50, 100, 200))

# Crear modelos utilizando el método train() de Caret
spotiKNN.modelo.knnRegNoMov <- train(popularity ~ ., 
                             data = spotiKNN.Datos.Entrenamiento, 
                             method = "knn", 
                             trControl = fitControl, 
                             tuneGrid = mygrid)
spotiKNN.modelo.knnRegNoMov
saveRDS(spotiKNN.modelo.knnRegNoMov, "knnRegNoMov.rds")
```

#### Normalizado z-score
Por otra parte, vamos a ver qué tal serían los resultados para el normalizado z-score. Primero sin quitar las 3 columnas de antes.

```{r, eval=FALSE}
set.seed(123)

# Definir las variables de entrada y salida
spotiKNN.Var.Salida.Usada <- c("popularity")
spotiKNN.Vars.Entrada.Usadas <- setdiff(names(spotiNormalizadoZScore), spotiKNN.Var.Salida.Usada)

# Crear una partición del 80% para entrenamiento y 20% para prueba
spotiKNN.Particion <- createDataPartition(spotiNormalizadoZScore[[spotiKNN.Var.Salida.Usada]], 
                                       p = 0.8, 
                                       list = FALSE,
                                       times = 1)

# Crear conjuntos de entrenamiento y prueba
spotiKNN.Datos.Entrenamiento <- spotiNormalizadoZScore[spotiKNN.Particion, ]
spotiKNN.Datos.Prueba <- spotiNormalizadoZScore[-spotiKNN.Particion, ]

# Usamos cross-validación 
fitControl <- trainControl(## 10-fold CV
                           method = "cv",
                           number = 10)
mygrid <- expand.grid(
  k = c(10, 50, 100, 200))

# Crear modelos utilizando el método train() de Caret
spotiKNN.modelo.knnRegZ <- train(popularity ~ ., 
                             data = spotiKNN.Datos.Entrenamiento, 
                             method = "knn", 
                             trControl = fitControl, 
                             tuneGrid = mygrid)
spotiKNN.modelo.knnRegZ
saveRDS(spotiKNN.modelo.knnRegZ, "knnRegNoMov.rds")
```

Y ahora para el dataset sin las 3 columnas y con z-score.
```{r, eval=FALSE}
set.seed(123)

# Definir las variables de entrada y salida
spotiKNN.Var.Salida.Usada <- c("popularity")
spotiKNN.Vars.Entrada.Usadas <- setdiff(names(spotifyNormNoMovementsZScore), spotiKNN.Var.Salida.Usada)

# Crear una partición del 80% para entrenamiento y 20% para prueba
spotiKNN.Particion <- createDataPartition(spotifyNormNoMovementsZScore[[spotiKNN.Var.Salida.Usada]], 
                                       p = 0.8, 
                                       list = FALSE,
                                       times = 1)

# Crear conjuntos de entrenamiento y prueba
spotiKNN.Datos.Entrenamiento <- spotifyNormNoMovementsZScore[spotiKNN.Particion, ]
spotiKNN.Datos.Prueba <- spotifyNormNoMovementsZScore[-spotiKNN.Particion, ]

# Usamos cross-validación 
fitControl <- trainControl(## 10-fold CV
                           method = "cv",
                           number = 10)
mygrid <- expand.grid(
  k = c(10, 50, 100, 200))

# Crear modelos utilizando el método train() de Caret
spotiKNN.modelo.knnRegNoMovZ <- train(popularity ~ ., 
                             data = spotiKNN.Datos.Entrenamiento, 
                             method = "knn", 
                             trControl = fitControl, 
                             tuneGrid = mygrid)
spotiKNN.modelo.knnRegNoMovZ
saveRDS(spotiKNN.modelo.knnRegNoMovZ, "knnRegNoMov.rds")
```


###Clasificación cluestering
Tamibén hemos pensado en clasificar la variable predictora como lo hacíamos en los primeros apartados y que sea "Poco Conocida", "Popular" y "Muy Popular" de esta forma el resultado será mucho más visual y representativo. De esta forma el número de clusters será 3.

```{r, eval=FALSE}
spotiNormalizadoCL <- spotiNormalizado
spotiNormalizadoCL$popularity_group <- cut(spotiNormalizado$popularity, 
                                         breaks = c(0, 30, 60, 90, 101), 
                                         labels = c("nada popular", "poco popular", "algo popular", "hit"),
                                         include.lowest = TRUE, 
                                         right = FALSE)
spotiNormalizadoCL <- spotiNormalizadoCL[, !names(spotiNormalizadoCL) %in% c("popularity")]

set.seed(123)

# Definir las variables de entrada y salida
spotiKNN.Var.Salida.Usada <- c("popularity_group")
spotiKNN.Vars.Entrada.Usadas <- setdiff(names(spotiNormalizadoCL), spotiKNN.Var.Salida.Usada)

# Crear una partición del 80% para entrenamiento y 20% para prueba
spotiKNN.Particion <- createDataPartition(spotiNormalizadoCL[[spotiKNN.Var.Salida.Usada]], 
                                       p = 0.8, 
                                       list = FALSE,
                                       times = 1)

# Crear conjuntos de entrenamiento y prueba
spotiKNN.Datos.Entrenamiento <- spotiNormalizadoCL[spotiKNN.Particion, ]
spotiKNN.Datos.Prueba <- spotiNormalizadoCL[-spotiKNN.Particion, ]

# Crear modelos utilizando el método train() de Caret
spotiKNN.modelo.knnCla <- train(popularity_group ~ ., 
                             data = spotiKNN.Datos.Entrenamiento, 
                             method = "knn", 
                             trControl = fitControl, 
                             tuneGrid = mygrid)

saveRDS(spotiKNN.modelo.knnCla, "knnCla.rds")
#print(spotiKNN.modelo.knn)
```


```{r}
knnCla_model = readRDS("knnCla.rds")
knnCla_model

#predicciones <- predict(knnCla_model, newdata = spotiKNN.Datos.Prueba)
# Calcular matriz de confusión
#cm <- confusionMatrix(predicciones, spotiKNN.Datos.Prueba$popularity)
#cm
```

```{r, eval=TRUE}
spotiNormalizadoNoMovCL <- spotifyNormNoMovements
spotiNormalizadoNoMovCL$popularity_group <- cut(spotifyNormNoMovements$popularity, 
                                         breaks = c(0, 30, 60, 90, 101), 
                                         labels = c("nada popular", "poco popular", "algo popular", "hit"),
                                         include.lowest = TRUE, 
                                         right = FALSE)
spotiNormalizadoNoMovCL <- spotiNormalizadoNoMovCL[, !names(spotiNormalizadoNoMovCL) %in% c("popularity")]

set.seed(123)

# Definir las variables de entrada y salida
spotiKNN.Var.Salida.Usada <- c("popularity_group")
spotiKNN.Vars.Entrada.Usadas <- setdiff(names(spotiNormalizadoNoMovCL), spotiKNN.Var.Salida.Usada)

# Crear una partición del 80% para entrenamiento y 20% para prueba
spotiKNN.Particion <- createDataPartition(spotiNormalizadoNoMovCL[[spotiKNN.Var.Salida.Usada]], 
                                       p = 0.8, 
                                       list = FALSE,
                                       times = 1)

# Crear conjuntos de entrenamiento y prueba
spotiKNN.Datos.Entrenamiento <- spotiNormalizadoNoMovCL[spotiKNN.Particion, ]
spotiKNN.Datos.Prueba <- spotiNormalizadoNoMovCL[-spotiKNN.Particion, ]

# Crear modelos utilizando el método train() de Caret
spotiKNN.modelo.knnClaNoMov <- train(popularity_group ~ ., 
                             data = spotiKNN.Datos.Entrenamiento, 
                             method = "knn", 
                             trControl = fitControl, 
                             tuneGrid = mygrid)

saveRDS(spotiKNN.modelo.knnClaNoMov, "knnClaNoMov.rds")
#print(spotiKNN.modelo.knn)
```

```{r, eval=TRUE}
spotiNormalizadoCL <- spotiNormalizadoZScore
spotiNormalizadoCL$popularity_group <- cut(spotiNormalizadoZScore$popularity, 
                                         breaks = c(0, 30, 60, 90, 101), 
                                         labels = c("nada popular", "poco popular", "algo popular", "hit"),
                                         include.lowest = TRUE, 
                                         right = FALSE)
spotiNormalizadoCL <- spotiNormalizadoCL[, !names(spotiNormalizadoCL) %in% c("popularity")]

set.seed(123)

# Definir las variables de entrada y salida
spotiKNN.Var.Salida.Usada <- c("popularity_group")
spotiKNN.Vars.Entrada.Usadas <- setdiff(names(spotiNormalizadoCL), spotiKNN.Var.Salida.Usada)

# Crear una partición del 80% para entrenamiento y 20% para prueba
spotiKNN.Particion <- createDataPartition(spotiNormalizadoCL[[spotiKNN.Var.Salida.Usada]], 
                                       p = 0.8, 
                                       list = FALSE,
                                       times = 1)

# Crear conjuntos de entrenamiento y prueba
spotiKNN.Datos.Entrenamiento <- spotiNormalizadoCL[spotiKNN.Particion, ]
spotiKNN.Datos.Prueba <- spotiNormalizadoCL[-spotiKNN.Particion, ]

# Crear modelos utilizando el método train() de Caret
spotiKNN.modelo.knnClaZ <- train(popularity_group ~ ., 
                             data = spotiKNN.Datos.Entrenamiento, 
                             method = "knn", 
                             trControl = fitControl, 
                             tuneGrid = mygrid)

saveRDS(spotiKNN.modelo.knnClaZ, "knnClaZ.rds")
#print(spotiKNN.modelo.knn)
```


```{r, eval=TRUE}
spotiNormalizadoNoMovZ_CL <- spotifyNormNoMovementsZScore
spotiNormalizadoNoMovZ_CL$popularity_group <- cut(spotifyNormNoMovementsZScore$popularity, 
                                         breaks = c(0, 30, 60, 90, 101), 
                                         labels = c("nada popular", "poco popular", "algo popular", "hit"),
                                         include.lowest = TRUE, 
                                         right = FALSE)
spotiNormalizadoNoMovZ_CL <- spotiNormalizadoNoMovZ_CL[, !names(spotiNormalizadoNoMovZ_CL) %in% c("popularity")]

set.seed(123)

# Definir las variables de entrada y salida
spotiKNN.Var.Salida.Usada <- c("popularity_group")
spotiKNN.Vars.Entrada.Usadas <- setdiff(names(spotiNormalizadoNoMovZ_CL), spotiKNN.Var.Salida.Usada)

# Crear una partición del 80% para entrenamiento y 20% para prueba
spotiKNN.Particion <- createDataPartition(spotiNormalizadoNoMovZ_CL[[spotiKNN.Var.Salida.Usada]], 
                                       p = 0.8, 
                                       list = FALSE,
                                       times = 1)

# Crear conjuntos de entrenamiento y prueba
spotiKNN.Datos.Entrenamiento <- spotiNormalizadoNoMovZ_CL[spotiKNN.Particion, ]
spotiKNN.Datos.Prueba <- spotiNormalizadoNoMovZ_CL[-spotiKNN.Particion, ]

# Crear modelos utilizando el método train() de Caret
spotiKNN.modelo.knnClaNoMovZ <- train(popularity_group ~ ., 
                             data = spotiKNN.Datos.Entrenamiento, 
                             method = "knn", 
                             trControl = fitControl, 
                             tuneGrid = mygrid)

saveRDS(spotiKNN.modelo.knnClaNoMovZ, "knnClaNoMovZ.rds")
#print(spotiKNN.modelo.knn)
```
### Grid Hiperparámetros
**Detallar una estrategia para la generación del grid de valores para hiperparámetros a usar.**

### Resultados
**Describir los resultados del algoritmo.**

# Apartado D
## Modelo Final