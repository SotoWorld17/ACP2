---
title: "Práctica 2"
author: "Lorena Romero y María Soto"
date: "2023-11-22"
output:
  
  html_document:
    df_print: paged
    highlight: kate
    number_sections: yes
    theme: spacelab
    toc: yes
    toc_float: yes
---

```{r}
library(ggplot2)
library(tidyverse)
library(gridExtra)
library(reshape2)
library(GGally)
library(ggfortify)
library(caret)
library(FactoMineR)
library(factoextra)
library(plotly)
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
colorspie <- c("skyblue", "plum3", "pink2", "sandybrown", "palegreen3")
colorpieborde <- c("skyblue4", "plum4", "pink3", "salmon3", "palegreen4")
```



Sys.setenv(RSTUDIO_PANDOC = "C:/Program Files/RStudio/resources/app/bin/quarto/bin/tools")

rmarkdown::render("Practica2.Rmd")



# Apartado A
## Descripción del conjunto de datos
**Describe brevemente el conjunto de entrenamiento.**

Vamos a trabajar sobre un conjunto de datos en el que se recogen las canciones más populares de Spotify a lo largo de un tiempo. Cada entrada recoge una amplia variedad de información de cada canción que analizaremos más adelante. Nuestro objetivo es utilizar estos datos para predecir la popularidad de canciones.

El conjunto de datos de entrenamiento consta de las siguientes variables categóricas:
`spotify_id`, `name`, `artists`, `country`, `is_explicit`,  `album_name`, `key`, `mode`, `time_signature`

Y, por otra parte, las siguientes variables numéricas:
`daily_rank`, `daily_movement`, `weekly_movement`, `snapshot_date`, `duration_ms`, `danceability`, `energy`, `loudness`, `speechiness`, `accousticness`,`liveness`, `instrumentalness` , `valence`, `tempo`, `popularity` y `album_release_date`

```{r}
spotify <- read.csv("spoti.csv", na.strings = "")

summary(spotify)
```
Sin embargo, aquí ya vemos que hay algunas variables que se toman como numéricas cuando hemos hablado de ellas como categóricas, y las fechas que son leídas como strings. Este problema lo trataremos después. 

Pero para hacer un pequeño análisis haremos un nuevo dataset donde no tendremos en cuenta los países. Después, haremos la media de popularidad de cada canción para ver cómo de populares son las canciones "mundialmente".

```{r}
spotify1 = spotify
#eliminamos columna paises
spotify1 = spotify1[,-c(1,8)]

# Calcula la media de la popularidad para cada canción
mean_popularity <- aggregate(popularity ~ name, data = spotify1, mean)

categories <- cut(spotify1$popularity, breaks = seq(0, 100, by = 10))
barplot(table(categories), main = "Recuento de Canciones por Intervalo de Popularidad", xlab = "Intervalo de Popularidad", ylab = "Recuento", col = colorspie)


```

Viendo este gráfico se nos ocurre para hacer nuestro pequeño análisis 3 grupos principales.

  - **Muy poco populares**, cuyo rango será de 0 a 40, de las canciones existentes hay muy pocas canciones poco populares.
  
  - **Populares**, cuyo rango de popularidad será de 40 a 80, este rango abarca canciones que han sido conocidas.
  
  - **Muy populares**, cuyo rango de popularidad sera de 80 a 100, las canciones más populares y conocidas.
  
Después de haber hecho esta división vamos a seguir haciendo este análisis sin tener en cuenta los países, sino la popularidad "mundial" tras haber hecho la media para no ver en el análisis tantos valores donde la mayoría van a ser repetidos. Para ello ahora vamos a empezar visualizando las variables categóricas que pueden tener algo de relación con `popularity`.

Vamos a utilizar analysis_data, donde en principio no vamos a tener en cuenta el país:
```{r}
#primero convertimos las fechas
spotify1$snapshot_date = as.Date(spotify1$snapshot_date)
spotify1$album_release_date = as.Date(spotify1$album_release_date)

#creamos analysis_data donde hacemos media de todas las variables, ya que si estas tienen algun remix por ejemplo
#cambiaran su valencia, energia pero por muy pocas centesimas.
analysis_data <- aggregate(cbind(popularity, daily_rank, weekly_movement,daily_movement, danceability, energy, loudness, key, speechiness, acousticness, instrumentalness, liveness, valence, tempo, time_signature, duration_ms) ~ name + artists + album_name + is_explicit + album_release_date + mode, data = spotify1, mean)

#ponemos las fechas como minimo, ya que nos interesa cuando entraron a la lista por primera vez
analysis_data2 <- aggregate(cbind(snapshot_date) ~  name + artists + album_name + is_explicit + album_release_date + mode , data = spotify1, min)

analysis_data$snapshot_date = analysis_data2$snapshot_date

analysis_data$popularity_group <- cut(analysis_data$popularity, breaks = c(0, 40, 80, 100), labels = c("Poco Conocida", "Popular", "Muy Popular"),include.lowest = TRUE)
analysis_data$popularity_group <- factor(analysis_data$popularity_group, levels = c("Poco Conocida", "Popular", "Muy Popular"))


```

- Variable `key`
Primero la pasamos a factor ya que actualmente se interpreta como numérica.
```{r}
analysis_data$key = factor(analysis_data$key)
myplot <- ggplot(data = analysis_data, aes(x = key, fill = popularity_group, color = popularity_group)) +
  geom_bar(alpha = 0.8, position = "dodge") +
  ggtitle("Relación entre la clave y la popularidad") +
  labs(x = "Key", y = "", fill = "Popularity Group") +
  scale_color_manual(values = colorpieborde, name = "Popularity Group") +
  scale_fill_manual(values = colorspie, name = "Popularity Group")
myplot

table(analysis_data$popularity_group, analysis_data$key)
```

Podemos ver como las canciones más populares son las que están compuestas en key 1. Esto nos hace pensar que esta variable si que estará relacionada con la popularidad debido a que puede aportar algo a las canciones que las haga más atractivas a pesar de que seguramente la persona que escucha la música no sabe la clave en la que está compuesta.

- `mode`

Analizando esta variable hemos descubierto que hay canciones que tienen un cambio de modo, es decir, que si una canción está en un principio en una tonalidad mayor otra variación de esta, un remix o incluso un error ocasiona que en algunas canciones haya cambios de modo. Entonces, si hacemos la media de esta variable agrupando las canciones por nombre y el resto de variables hay alguna cuyo modo varía, dando así valores intermedios, por lo que en el agrupamiento anteriormente hemos decidido que no se haga la media de esta variable.

```{r}
analysis_data$mode = factor(analysis_data$mode)
myplot <- ggplot(data = analysis_data, aes(x = mode, fill = popularity_group, color = popularity_group)) +
  geom_bar(alpha = 0.8, position = "dodge") +
  ggtitle("Relación entre el modo y la popularidad") +
  labs(x = "Mode", y = "", fill = "Popularity Group") +
  scale_color_manual(values = colorpieborde, name = "Popularity Group") +
  scale_fill_manual(values = colorspie, name = "Popularity Group")
myplot

table(analysis_data$popularity_group, analysis_data$mode)
```

También vemos que aquí hay diferencia de canciones, hay aproximadamente 70 canciones más que son muy populares debido al modo en el que están compuestas. Por otro lado, hay casi 200 canciones más que son populares compuestas en el modo 0. Sin embargo, hay más canciones en el modo 1 que tienen cierta popularidad que en el modo 0.
Por lo que esta variable también puede estar relacionada.


- `is_explicit`

```{r}
analysis_data$is_explicit = factor(analysis_data$is_explicit)
myplot <- ggplot(data = analysis_data, aes(x = is_explicit, fill = popularity_group, color = popularity_group)) +
  geom_bar(alpha = 0.8, position = "dodge") +
  ggtitle("Relación entre el modo y la popularidad") +
  labs(x = "Explicita", y = "", fill = "Popularity Group") +
  scale_color_manual(values = colorpieborde, name = "Popularity Group") +
  scale_fill_manual(values = colorspie, name = "Popularity Group")
myplot

table(analysis_data$popularity_group, analysis_data$is_explicit)
```
La mayoría de canciones no explícitas son más populares que las canciones explícitas, por lo que quizás esto también juega un papel importante en la popularidad.

- `name`, `artists`, `album_name` 
Aunque estas variables no van a jugar un papel fundamental en nuestro modelo, es más, vamos a prescindir de ellas ya que lo que pretendemos es saber si una canción se hará o no famosa debido a sus atributos intrínsecos. Vamos a mostrar las canciones más populares, los artistas, y el nombre del album

```{r}
analysis_datasorted = analysis_data[order(-analysis_data$popularity),]

N<-10
artistastop = analysis_datasorted$artists[1:10]
cat("Artistas más populares\n")
artistastop
```
Estos son el top de artistas con más popularidad en este momento. Cada uno tiene diferentes canciones populares:

```{r}
popularity_counts <- table(analysis_datasorted$artists)

cat("Número de canciones en el dataset para cada artista:\n")
for (artist in artistastop) {
  cat(artist, ":", popularity_counts[artist], "canciones en la lista\n")
}
```
Y estas son las canciones y el nombre del álbum:
```{r}
canciones <- data.frame(
  Artista = analysis_datasorted$artists[1:10],
  Nombre = analysis_datasorted$name[1:10],
  Álbum = analysis_datasorted$album_name[1:10]
)
canciones
```
Esto no coincide con el ranking y somos conscientes de ello pero todavía no hemos analizado esas partes. Como recordatorio, esto solo lo hemos hecho para hablar un poco de los datos, estas tres variables no las vamos a tener muy en cuenta de ahora en adelante.

***Variables continuas***

- `daily_rank`

```{r}
analysis_data$daily_rank = round(analysis_data$daily_rank)

analysis_data$daily_rank_group <- cut(analysis_data$daily_rank, breaks = c(0, 10, 20, 30, 40, 50), labels = c("Top 10", "Top 20", "Top 30", "Top 40", "Top 50"),include.lowest = TRUE)

myplot = ggplot(data=analysis_data, aes(x=daily_rank_group, fill=popularity_group, color = popularity_group)) +
  geom_bar(alpha=0.8, position="dodge")+
  labs(x = "Daily_Rank",y="") +
  scale_color_manual(values = colorpieborde, name="popularity")+
  scale_fill_manual(values = colorspie, name="popularity")
myplot
```
Esto nos hace pensar que el ranking actual no significa que una canción sea muy popular. Estas van a ir ganando popularidad quizás con el tiempo que permanezca en la lista, pero las 10 primeras no se acercan en absoluto a las canciones más populares. 

- `daily_movement`

```{r}
analysis_data$daily_movement = round(analysis_data$daily_movement)

analysis_data$daily_movement_group <- cut(analysis_data$daily_movement, breaks = c(-10, 0, 5, 10, 20, 30, 40, 50), labels = c("Baja puestos", "Se mantiene", "Sube puestos", "Sube bastantes puestos", "Sube muchos", "Se hace famosísima de repente", "Da un boom"),include.lowest = TRUE)

myplot = ggplot(data=analysis_data, aes(x=daily_movement_group, fill=popularity_group, color = popularity_group)) +
  geom_bar(alpha=0.8, position="dodge")+
  labs(x = "Daily Movemente",y="") +
  scale_color_manual(values = colorpieborde, name="popularity")+
  scale_fill_manual(values = colorspie, name="popularity")+
  theme(axis.text.x = element_text(angle = 15, hjust = 1))
myplot
```
El movimiento diario nos muestra que las canciones que se mantienen son las más populares, esto es seguramente por aguantar más tiempo en un ranking superior.

- `weekly_movement`

```{r}
analysis_data$weekly_movement = round(analysis_data$weekly_movement)

analysis_data$weekly_movement_group <- cut(analysis_data$weekly_movement, breaks = c(-20, 0, 5, 10, 20, 30, 40, 80), labels = c("Baja puestos", "Se mantiene", "Sube puestos", "Sube bastantes puestos", "Sube muchos", "Se hace famosísima de repente", "Da un boom"),include.lowest = TRUE)

myplot = ggplot(data=analysis_data, aes(x=weekly_movement_group, fill=popularity_group, color = popularity_group)) +
  geom_bar(alpha=0.8, position="dodge")+
  labs(x = "Weekly Movemente",y="") +
  scale_color_manual(values = colorpieborde, name="popularity")+
  scale_fill_manual(values = colorspie, name="popularity")+
  theme(axis.text.x = element_text(angle = 15, hjust = 1))
myplot
```
Aquí vemos que para algunas canciones hay NA's pero este análisis no es con el conjunto de datos definitivo que vamos a tratar por lo que no las estamos teniendo en cuenta. Podemos ver como al igual que antes son las canciones que se mantienen las que más populares son.


- `snapshot_date` interesante análisis junto `album_realease_date`

Creemos que es interesante analizar el tiempo que tarda una canción en entrar en el dataset porque va a empezar a ganar popularidad para ello vamos a hacer una columna con el número de días que una canción tarda en hacerse famosa

```{r}
analysis_data$snapshot_date = as.Date(analysis_data$snapshot_date)
analysis_data$album_release_date = as.Date(analysis_data$album_release_date)

diferencia_dias = as.numeric(analysis_data$snapshot_date - analysis_data$album_release_date)
analysis_data$numDiasFama = diferencia_dias

analysis_data$numDiasFama = ifelse(analysis_data$numDiasFama <= 0, 0, analysis_data$numDiasFama)

analysis_data$numDiasFama_group <- cut(analysis_data$numDiasFama, breaks = c(-1, 1, 10, 30, 60, 90, 120, 99999), labels = c("Entra al salir", "10 dias", "1 mes", "2 meses", "3 meses", "4 meses", "+"),include.lowest = TRUE)
sum(is.na(analysis_data$numDiasFama))
sum(is.na(analysis_data$numDiasFama_group))
myplot = ggplot(data=analysis_data, aes(x=numDiasFama_group, fill=popularity_group, color = popularity_group)) +
  geom_bar(alpha=0.8, position="dodge")+
  labs(x = "Número Días Hasta Dataset",y="") +
  scale_color_manual(values = colorpieborde, name="popularity")+
  scale_fill_manual(values = colorspie, name="popularity")
myplot
```
Son muy pocas las canciones que nada más salir entran al dataset de spotify. La mayoría de canciones que entran tienen mucha antigüedad siendo gran parte bastante populares. Además, cabe destacar que la popularidad de las que entran a los 10 dias de salir es baja.


- **CARACTERÍSTICAS DE LAS CANCIONES**
`duration_ms`, `danceability`, `energy`, `loudness`, `speechiness`, `accousticness`, `liveness`, `instrumentalness`, `valence`, `tempo`, `time_signature`

```{r}
analysisContinuas= analysis_data[ , c("popularity_group", "duration_ms", "danceability","energy", "loudness", "speechiness", "acousticness", "liveness", "instrumentalness", "valence", "tempo")]
mymelt=melt(analysisContinuas, id.vars=1, value.name="FeatureValue", variable.name="Feature")

myplot = ggplot(data=mymelt, aes(x=FeatureValue, fill=popularity_group, color = popularity_group)) +
  geom_density(alpha=0.8)+
  ggtitle("Relación entre las variables continuas y la variable de clase")+
  labs(x = "",y="", fill = "") +
  scale_color_manual(values = colorpieborde, name="")+
  scale_fill_manual(values = colorspie, name="")+
  facet_wrap(~ Feature, ncol=3, scales = "free")
myplot
```
Nos sorprende ver que todas estas variables parecen tener una gran correlación con la variable de clase. Ya que podemos verlas todas superpuestas. Sin embargo, vemos que hay valores muy dispersos y nos gustaría trabajar con ellos, quizá, en la misma escala; es por esto que más adelante seguramente se normalicen estos valores.

Creemos que además de con la popularidad, estas variables van a estar bastante correlacionadas entre sí.

```{r}
analysisContinuas= analysis_data[ , c("duration_ms", "danceability","energy", "loudness", "speechiness", "acousticness", "liveness", "instrumentalness", "valence", "tempo")]
corrplot::corrplot(cor(analysisContinuas))

```
Y tal como imaginamos podemos ver la relación que existe entre estas variables. Por ejemplo la relación negativa que hay entre `acousticness` y `energy` que puede ser debido a que el acústico transmite menos energía. O que las canciones donde hay energía sean más "ruidosas". Nos parece muy interesante que, en general, la mayoría están relacionadas.


- Por último, `time_signature`
```{r}
myplot = ggplot(data=analysis_data, aes(x=time_signature, fill=popularity_group, color = popularity_group)) +
  geom_bar(alpha=0.8, position="dodge")+
  labs(x = "Time Signature",y="") +
  scale_color_manual(values = colorpieborde, name="popularity")+
  scale_fill_manual(values = colorspie, name="popularity")
myplot
```
Vemos como casi todas las canciones tienen un `time_signature` de 4, y que no hay ninguna con 2. Por lo tanto seguramente esta variable sea un poco indiferente a la hora de conocer la popularidad. Pero nos ayudará a determinar que la mayoría de canciones se hacen populares cuando su `time_signature` es de 4.

Antes de comenzar con las preguntas del apartado 1, nos gustaría hacer un pequeño PCA para mostrar si con las variables que tenemos numéricas seríamos capaces de determinar algo de información sobre la popularidad.

```{r}
analysis_pca = analysisContinuas
analysis_pca$daily_rank = analysis_data$daily_rank
analysis_pca$weekly_movement = analysis_data$weekly_movement 
analysis_pca$daily_movement = analysis_data$daily_movement
analysis_pca$time_signature = analysis_data$time_signature
analysis_pca$numDiasFama = analysis_data$numDiasFama
analysis_pca_estatus = analysis_data$popularity_group

# PCA
pca_result <- prcomp(analysis_pca, scale = TRUE)
row.names(pca_result$x) = analysis_pca_estatus
pcas = as.data.frame(pca_result$x, stringsAsFactors =F)
pcas = cbind(ESTATUS = analysis_pca_estatus,pcas)
```

```{r}
ggplot(pcas, aes(PC1, PC2, color = ESTATUS, shape=ESTATUS)) +
  geom_point(size = 1, alpha=0.6) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  geom_vline(xintercept = 0, linetype = "dashed") +
  scale_color_manual(values = colorspie) +
  scale_shape_manual(values = c(17, 16, 15)) +
  xlab("Primera componente principal") +
  ylab("Segunda componente principal") +
  ggtitle("Las dos primeras componentes principales de titanicData") +
  guides(color = guide_legend(title = "Estado de Popularidad"), shape = guide_legend(title = "Estado de Popularidad")) +
  theme_minimal() +
  theme(legend.position = "top")
```

```{r}
autoplot(pca_result, data=analysis_data, cex = 0.7, alpha=0.6, color = "popularity_group",
         loadings = TRUE, loadings.colour = 'gold',
         loadings.label = TRUE, loadings.label.size = 4, loadings.label.colour = 'mediumvioletred')

fviz_pca_var(pca_result, col.var = "contrib",
             gradient.cols = c("white", "blue", "red"), 
             repel = TRUE)
```

Debido a la gran cantidad de datos es casi imposible ver lo que nos muestra este PCA, aunque podemos ver la parte representativa de cada componente en el análisis. Tambien se nos dice que variables como weekly_movement, energy, loudness... presentan una gran variación para nuestros datos.

```{r}
(VE <- pca_result$sdev^2)
PVE <- VE / sum(VE)
cumsum(round(PVE, 2))
```
Vemos que con 11 de estas variables ya seríamos capaces de procesar un 98% de la popularidad. Y eso que solo estamos trabajando con las numéricas, 12 variables sobre las 26 disponibles inicialmente son muy buenas para entrenar un modelo. Lo que nos lleva a pensar que quizás no necesitemos de las otras variables para hacer un buen trabajo.

Finalmente vamos a analizar un poco de la variable `country` la que hemos eliminado anteriormente sin tener reparo en que esta variable tendrá canciones con popularidad distinta en cada país, vamos a quedarnos con aquellas con mayor popularidad y por lo tanto vamos a ver solo un poco de como afectan las variables numéricas a los distintos países.

```{r}
library(rnaturalearth)
library(ggplot2)
library(purrr)
library(cowplot)

analysis_data <- aggregate(cbind(popularity, daily_rank, weekly_movement,daily_movement, danceability, energy, loudness, key, speechiness, acousticness, instrumentalness, liveness, valence, tempo, time_signature, duration_ms) ~ name + artists + album_name + is_explicit + album_release_date + mode + country, data = spotify, mean)

analysis_data2 <- aggregate(cbind(snapshot_date) ~  name + artists + album_name + is_explicit + album_release_date + mode + country , data = spotify, min)

analysis_data$snapshot_date = analysis_data2$snapshot_date

# Cargar datos de límites de países
world <- ne_countries(returnclass = "sf")

world = world[, c("iso_a2", "geometry")]

# Crear un conjunto de datos de ejemplo
spotify_mean <- data.frame(
  country= analysis_data$country,
  popularity = analysis_data$popularity,
  is_explicit = analysis_data$is_explicit,
  duration_ms = analysis_data$duration_ms, 
  danceability = analysis_data$danceability,
  energy = analysis_data$energy,
  loudness = analysis_data$loudness,
  speechiness = analysis_data$speechiness,
  liveness = analysis_data$liveness,  
  instrumentalness = analysis_data$instrumentalness,
  valence = analysis_data$valence, 
  tempo = analysis_data$tempo
)

# Quedarse con las filas en las que la popularidad es mayor que 80
spotify_mean <- spotify_mean[spotify_mean$popularity > 80, ]

# Unir datos de Spotify con datos del mundo
world_spotify <- merge(world, spotify_mean, by.x = "iso_a2", by.y = "country", all.x = FALSE)

# Lista de variables a usar en cada mapa
variables <- c("duration_ms", "danceability", "energy", "loudness", "speechiness", "liveness", "valence", "tempo")

# Crear una lista de gráficos usando purrr::map
maps <- map(variables, function(var) {
  ggplot() +
    geom_sf(data = world_spotify, aes_string(fill = var)) +
    scale_fill_gradient(low = "lightyellow", high = "sandybrown") +
    theme_minimal() +
    labs(title = var)  # Título con el nombre de la variable
})

plot_grid(plotlist = maps, ncol = 3)
```
Aqui podemos ver como la 'danceability' de las canciones más populares sera distinta en cada país. Y otras características como por ejemplo la `valence` en Oceanía disfrutaran de canciones más calmadas que por ejemplo en sur América.

```{r}
rm(analysis_data, analysis_data2, analysis_datasorted,mean_popularity, canciones, mymelt, artist, pcas, pca_result, spotify_mean, spotify1, world, world_spotify, myplot, maps, analysisContinuas, analysis_pca, analysis_pca_estatus, artistastop, categories, diferencia_dias, N, popularity_counts, PVE, variables, VE)
```

Después de haber hecho este pequeño análisis, cuyos datos son una muestra representativa del conjunto inicial pasamos a responder las preguntas del apartado A.

**Describe además, los atributos predictores del conjunto y la variable a predecir. Divide la descripción de los atributos en cuatro grupos, a saber. Justifica el porqué entiendes que cada atributo tiene o no relación con `popularity`.**

**1. predictores numéricos que, a priori, no tienen relación alguna con `popularity` y por tanto no son útiles para su predicción.**

Vamos a nombrar cada variable que pensamos que no tienen relación con su correspondiente justificación.

- `album_release_date`: no estamos muy seguras de si esta variable se tratará más adelante o si tendrá relación con la popularidad.
- `snapshot_date`: La fecha en la que se recogieron los datos podría ser importante porque la popularidad de una canción puede variar con el tiempo aunque no estamos muy seguro de ellos.

**2. Predictores numéricos que pueden aportar algo a la predicción de `popularity` y predictores categóricos.**

Como hemos hecho en el apartado anterior, vamos ir explicanco junto a la variable que creemos que sí puede aportar el porqué de esta creencia.

Para los predictores numéricos:

- `daily_rank`: La posición diaria en el ranking puede ser un indicador importante de la popularidad de una canción. Si una canción ocupa constantemente un lugar alto es probable que sea popular.

- `daily_movement`: El cambio diario de la posición podría indicar tendencias en la popularidad de la canción, en caso de subir seguramente indique un aumento de popularidad.

- `weekly_movement`: Es parecido al anterior, pero a más largo plazo.

- `valence`: La media de positivismo transmitido por la canción podría influir en su atractivo general, las cancioens más alegres o las más triste suelen ser las más populares pero si no trasmites nada seguramente no sea popular.

- `tempo`: El número de beats por minuto puede influir en la percepción de energía de una canción y ser más popular.

- `energy`: La energía de la canción podría ser un factor calve en su atractivo puesto que las canciones más enérgicas podrían tener mayor probabilidad de ser populares.

- `time_signature`: Creemos que el nivel en una esacala de ritmo musical tiene relación con las dos anteriores por lo que pensamos que puede ser relevante para la popularidad de una canción.

- `speechiness`: La presencia de palabra hablada en una canción es muy importante pues la gran mayoría de canciones (por no decir todas) que están en los rankings de popularidad suelen ser todas con letra.

- `instrumentalness`: La predominandia de la instrumentación sobre la voz pordría influir de la misma forma que la anterior.

- `duration_ms`: como hemos visto antes esta variable podria estar relacionada con la popularidad

- `liveness`: el porcentaje de una canción que se grabó en vivo o en estudio influirá en la popularidad.

- `acousticness`: la calidad acústica de la música es algo que tambien tendra relación.

- `loudness`: pensamos que el nivel de decibelios al que fue grabada la canción importará para la popularidad.

- `danceability`: La capacidad de una canción para ser baildad podría ser una factor importante.


Y para los predictores categóricos:

- `mode`: Si la canción está en modo mayor o menos podría influir en la percepción emocional y, por tanto, en su popularidad.

- `is_explicit`: La presencia de lenguaje explícito podría atraet a ciertos públicos y afectar. Por ejemplo, muchas canciones muy populares latinoamericanas tienen un alto porcentaje de palabras sexuales y escenarios explícitos y, a veces, cuan más explícito es más repercusión tiene. Por otra parte, canciones con un lenguaje explícito de violencia no suelen ser populares por motivos obvios.

- `key`: pensamos que la escala en la que está compuesta podrá afectar a la popularidad.

**3. Relacionados con `popularity`.**

Pensamos que las variables que más relación tienen con la popularidad son los puestos que tiene una canción diariamente y semanal y sus movimientos entre los puestos. `daily_rank`, `daily_movement` y `weekly_movement`.


**4. No relacionados.**

- `artists`: El artista podría ser un factor importante pues artitas más reconocidos tienen más propabilidad de producir canciones populares. Pero, no nos servira en nuestro estudio ya que estamos planteando hacer un reconocimiento para canciones nuevas que no tienen por que ser de artistas conocidos, por eso no nos va a aportar nada en el modelo que vamos a entrenar.

- `spotify_id`: no tiene relación porque es simplemente una forma de identificar la canción.

- `name`: creemos que el nombre de la canción no tendrá relevancia porque muchas de las canciones que más escuchamos en nuestro día a día porque se han hecho ``virales'' gracias a las redes sociales no conocemos sus nombres en un principio. 

- `country`: la ubicación geográfica del origen de la canción no tiene una correlación evidente con su popularidad ya que la mayoría de canciones que escuchamos que son populares no sabemos cuál es su origen o no nos interesa para porder disfrutarla.
 
- `album_name`: muchas de las canciones no más populares no salen ni en un álbum y en general, la gente no se fija en el álbum en sí al que pertenece una canción, simplemente en la canción si les gusta. 

# Apartado B
## Preparación de datos

Para empezar vamos a eliminar la variable X, ya que creemos que es una variable nula que se ha colado en la lectura del csv, después vamos a pasar a variables categóricas key y mode ya que actualmente se consideran como numéricas. Y convertiremos las clases `album_release_date` y `snapshot_date` en fechas, en lugar de cadenas para despues poder tratar con ellas.
```{r}
spotify = spotify[,-1]

spotify$mode = factor(spotify$mode)
spotify$key = factor(spotify$key)

spotify$album_release_date = as.Date(spotify$album_release_date)
spotify$snapshot_date = as.Date(spotify$snapshot_date)

```

A continuación vamos a mirar los NA's que presentan nuestras variables.
```{r}
colSums(is.na(spotify))
```

Después de haber mirado un poco por encima el dataset, sabemos que los 21 valores nulos que se muestran con `name` y `artists` son los mismos, al igual que los 22 de `album_release_date` y `album_name`. Además 21 de ellos coinciden como nulos con `name` y `album_name`. 

Aquí podemos ver la cantidad de nulos que coinciden con `name` y `artists`

```{r}
table(is.na(spotify$name), is.na(spotify$artists))
```

Aquí vemos la cantidad de nulos que coinciden con `album_release_date` y `album_name` 

```{r}
table(is.na(spotify$album_release_date), is.na(spotify$album_name))
```

y aquí la cantidad de nulos que coinciden con `name`y `album_release_date`

```{r}
table(is.na(spotify$name), is.na(spotify$album_name))
```
Lo que vamos a hacer es eliminar los 22 valores nulos de estas distintas filas, ya que consideramos que son pocos los datos de los que vamos a prescindir.
```{r}
spotify <- spotify[complete.cases(spotify$album_release_date), ]

colSums(is.na(spotify))
```
Ahora podemos ver que solo quedan 1452 nulos en la columna `country` del dataset. La estrategia que vamos a utilizar es omitir estas filas también, ya que contando actualmente con 105647 datos, creemos que podemos prescindir de estos 1452 nulos, dejándonos así con 104195 valores para nuestro trabajo de investigación.
```{r}
table(is.na(spotify$country))
spotify <- spotify[complete.cases(spotify$country), ]
```



Otra idea que se nos ocurre es tener en cuenta los días que hay desde que se publica una canción hasta que esta obtiene una nueva posición en el ranking, la forma en la que podemos hacer esto es restar `snapshot_date` con `album_release_date` y tener así un registro del número de días que una canción tardó en hacerse popular, como la fecha de salida de una canción puede ser anterior a la salida de un álbum pondremos como 0 aquellas canciones que tienen como diferencia de fechas un valor negativo.

```{r}
diferencia_dias = as.numeric(spotify$snapshot_date - spotify$album_release_date)

spotify$diferencia_dias = diferencia_dias
spotify$diferencia_dias = ifelse(spotify$diferencia_dias < 0, 0, spotify$diferencia_dias)
```

Otra idea que nos surge al observar los datos es que distintas canciones están repetidas y tienen una diferente popularidad dependiendo del país, al principio pensamos que sería una buena idea organizarlas dependiendo del continente en la que esta canción se volvió popular. Recapacitando sobre esta primera interpretación, pensamos que no es tan buena idea, por ejemplo las personas en Sudamérica , no escucharán la misma música que las personas en Norteamérica  debido a que el idioma más hablado en ambas áreas es distinto. Por lo que organizaremos `country` en una nueva columna, dividiendo los países del continente americano en northAmerica y southAmerica. Para ello vamos a visualizar los distintos paises primeros.

```{r}
diccionario_continentes <- c(
  AE = "AS", AR = "SA", AT = "EU", AU = "OC",
  BE = "EU", BG = "EU", BO = "SA", BR = "SA",
  BY = "EU", CA = "SA", CH = "EU", CL = "SA",
  CO = "SA", CR = "SA", CZ = "EU", DE = "EU",
  DK = "EU", DO = "SA", EC = "SA", EE = "EU",
  EG = "AF", ES = "EU", FI = "EU", FR = "EU",
  GB = "EU", GR = "EU", GT = "SA", HK = "AS",
  HN = "SA", HU = "EU", ID = "AS", IE = "EU",
  IL = "AS", IN = "AS", IS = "EU", IT = "EU",
  JP = "AS", KR = "AS", KZ = "AS", LT = "EU",
  LU = "EU", LV = "EU", MA = "AF", MX = "NA",
  MY = "AS", NG = "AF", NI = "SA", NL = "EU",
  NO = "EU", NZ = "OC", PA = "SA", PE = "SA",
  PH = "AS", PK = "AS", PL = "EU", PT = "EU",
  PY = "SA", RO = "EU", SA = "AS", SE = "EU",
  SG = "AS", SK = "EU", SV = "SA", TH = "AS",
  TR = "AS", TW = "AS", UA = "EU", US = "NA",
  UY = "SA", VE = "SA", VN = "AS", ZA = "AF"
)

spotify$continent = diccionario_continentes[spotify$country]
```
A continuación, como hemos visto que muchas canciones se repiten en los distintos paises, vamos a eliminar los duplicados que comparten el nombre de la canción, el país y la popularidad de los datos; consideramos una interesante estrategia, dejando la primera y ultima aparición de cada dato y aquellos datos que no están repetidos. Al juntarlos, sin embargo, hemos ocasionado que se repitan algunas filas, para ello utilizamos `unique`, en la que tenemos en cuenta todas las variables por lo que eliminamos todas las filas que se repiten completamente dejando solo una instancia de ellas.


```{r}
comprobar_duplicados = spotify[, c("name","country","popularity")] 
# sum(duplicated(comprobar_duplicados))

spotify_primera_aparicion = spotify[!duplicated(comprobar_duplicados), ]

spotify_ultima_aparicion = spotify[!duplicated(comprobar_duplicados, fromLast = TRUE), ]

spotify_pyu <- rbind(spotify_primera_aparicion, spotify_ultima_aparicion)

spotifyNoDup =  spotify[!duplicated(comprobar_duplicados) & !duplicated(comprobar_duplicados, fromLast = TRUE), ]

# 
# comprobar_duplicados2 = spotifyNoDup[, c("name","country","popularity", "continent")] 
# sum(duplicated(comprobar_duplicados2))
# 

spotifyFinal = rbind (spotify_pyu, spotifyNoDup)
# (duplicated(comprobar_duplicados2))
# sum(duplicated(spotifyFinal))

spotifyFinal_sin_duplicados <- unique(spotifyFinal)
```

```{r}
spotify = spotifyFinal_sin_duplicados
rm(spotifyFinal_sin_duplicados, spotify_primera_aparicion, spotify_ultima_aparicion, spotify_pyu, spotifyFinal, spotifyNoDup, diferencia_dias, diccionario_continentes, comprobar_duplicados)
```

Hasta ahora no hemos hecho nada más que añadir columnas, pero sabemos de antemano que no todas ellas nos van a ser de utilidad para entrenar nuestro modelo. Sin embargo, no las hemos eliminado anteriormente para hacer la limpieza de datos pero ahora procedemos a quitar las columnas `spotify_id`, `name`, `artists`, `album_name`, `album_release_date`   
```{r}
spotify = spotify[, -c(1,2,3,12,13)]
```

Anteriormente hemos agrupado los argumentos `album_release_date` y `snapshot_date` en la variable que recoge la diferencia de días. Por lo que ahora también consideramos oportuno quitar la variable `snapshot_date` ya que ya tenemos en el dataset el número de días que la canción ha tardado en tener la respectiva `popularity`.


```{r}
spotify = spotify[, -5]
```


Cómo explicábamos antes, hemos considerado crear la variable `continente` para hacer una mayor limpieza de datos, pero debido a que se nos ha ocurrido la otra alternativa para hacer limpieza de duplicados y no cargarnos tantos datos, consideramos que ya no nos va a hacer falta `continent`, al igual que `country`. Como el objetivo es dada una canción saber si esta se va a hacer famosa o no, no vamos a tener en cuenta el país o continente.

```{r}
spotify = spotify[, -c(4,21)]
```

**Respóndase a las siguientes preguntas en relación a la preparación de datos.**

**- ¿Qué predictores habría que normalizar? ¿Por qué? ¿Cuál sería la estrategia de normalización en cada caso?**
Los predictores que habría que normalizar son `duration_ms`, `loudness`, `tempo`?, `diferencia_dias`.

-`duration_ms`: pensamos que  una mejor forma de analizar la duración de las canciones es si normalizamos estos valores con segundos en vez de milisegundos pues así no tenemos datos muy específico que, además, no creemos que una diferencia de milisegundos entre las canciones afecte a los resultados y de esta forma es más fácil comparar las duraciones pues en spotify el valor mínimo que se guarda de cara al público es en segundos.

```{r}
spotiNormalizado = spotify
spotiNormalizado$duration_sec <- trunc(spotiNormalizado$duration_ms / 1000)
spotiNormalizado <- subset(spotiNormalizado, select = -c(duration_ms))
```


-`loudness`: vamos a normalizar los decibelios en [0,1] pues los valores van de [-31.042,1.155] y para ello sumaremos a cada dato 31.042 y lo dividiremos entre (1.155+31.042).

```{r}
max <- max(spotiNormalizado$loudness)
min <- min(spotiNormalizado$loudness)
spotiNormalizado$loudness <- (spotiNormalizado$loudness-min)/(max-min)
```


-`tempo`: el tempo lo vamos a normalizar de una forma parecida al anterior pues su rango de valores es [47.914,217.969] y nos interesaría que estuviese en [0,1] por lo que le restaremos 47.914 al valor del dato y lo dividiremo entre (47.914+217.969).

```{r}
max <- max(spotiNormalizado$tempo)
min <- min(spotiNormalizado$tempo)
spotiNormalizado$tempo <- (spotiNormalizado$tempo-min)/(max-min)
```

**- ¿Podría ser interesante transformar algún atributo o grupos de atributos en uno nuevo? ¿Por qué?**

**AQUÍ LO MISMO DEBERÍAN IR ALGUNAS PARTES DEL PRINCIPIO QUE HAS HECHO** 

**- ¿Cómo podría aprovecharse el carácter secuencial de los datos?**


# Apartado C
## Fucnionamiento
**Explicar brevemente el tipo de modelo que genera el algoritmo, y cuál es la estrategia de dicho algoritmos para construir el modelo.**

## Requisitos
**Indicar si el algoritmo en cuestión tiene algún requisito en cuanto a si se han de preprocesar los datos (e.g. escalado, imputación de valores nulos, etc.) y cómo. Explicar cómo se ha tenido en cuenta estos requisitos a la hora de generar los datos de training específicos para este algoritmo.**

## Descripción de hiperparámetros
**Identificar y explicar cada uno de sus parámetros de configuración.**

## Grid Hiperparámetros
**Detallar una estrategia para la generación del grid de valores para hiperparámetros a usar.**

## Resultados
**Describir los resultados del algoritmo.**

# Apartado D
## Modelo Final